{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo A para clasificación de imagenes\n",
    "\n",
    "#### Jeffrey Daniel Leiva Cascante 2021016720\n",
    "#### Richard Osvaldo León Chinchilla 2019003759\n",
    "\n",
    "## Inicialización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de imágenes de entrenamiento: 211\n",
      "Número de imágenes de validación: 37\n",
      "Número de imágenes de test: 66\n",
      "Loader de entrenamiento: 7\n",
      "Loader de validación: 2\n",
      "Loader de test: 3\n",
      "{'Covid': 0, 'Normal': 1, 'Viral Pneumonia': 2}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), # Resnet es de 224x224\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5]),\n",
    "    transforms.RandomRotation(20),  # Rotación aleatoria\n",
    "    transforms.RandomHorizontalFlip(),  # Inversión horizontal aleatoria\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),  # Variación de brillo y contraste\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5]),\n",
    "    \n",
    "])\n",
    "\n",
    "# Cargamos el dataset de entrenamiento para cada dataset\n",
    "train_dataset = datasets.ImageFolder(root='./Covid19-dataset/train', transform=transform)\n",
    "train_dataset_bilateral = datasets.ImageFolder(root='./Covid19-dataset-bilateral/train', transform=transform)\n",
    "train_dataset_canny = datasets.ImageFolder(root='./Covid19-dataset-canny/train', transform=transform)\n",
    "\n",
    "# Cargamos el dataset de test para cada dataset\n",
    "test_dataset = datasets.ImageFolder(root='./Covid19-dataset/test', transform=transform_test)\n",
    "test_dataset_bilateral = datasets.ImageFolder(root='./Covid19-dataset-bilateral/test', transform=transform_test)\n",
    "test_dataset_canny = datasets.ImageFolder(root='./Covid19-dataset-canny/test', transform=transform_test)\n",
    "\n",
    "val_percent = 0.15 # Porcentaje de imágenes que se usarán para validación\n",
    "\n",
    "# Calculamos el tamaño de los conjuntos de entrenamiento y validación\n",
    "val_size = int(val_percent * len(train_dataset))\n",
    "train_size = len(train_dataset) - val_size\n",
    "\n",
    "val_size_bilateral = int(val_percent * len(train_dataset_bilateral))\n",
    "train_size_bilateral = len(train_dataset_bilateral) - val_size_bilateral\n",
    "\n",
    "val_size_canny = int(val_percent * len(train_dataset_canny))\n",
    "train_size_canny = len(train_dataset_canny) - val_size_canny\n",
    "\n",
    "# Se divide el dataset en dos\n",
    "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
    "train_dataset_bilateral, val_dataset_bilateral = random_split(train_dataset_bilateral, [train_size_bilateral, val_size_bilateral])\n",
    "train_dataset_canny, val_dataset_canny = random_split(train_dataset_canny, [train_size_canny, val_size_canny])\n",
    "\n",
    "# Creamos los dataloaders para cada dataset\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "train_loader_bilateral = DataLoader(train_dataset_bilateral, batch_size=32, shuffle=True)\n",
    "val_loader_bilateral = DataLoader(val_dataset_bilateral, batch_size=32, shuffle=False)\n",
    "test_loader_bilateral = DataLoader(test_dataset_bilateral, batch_size=32, shuffle=False)\n",
    "\n",
    "train_loader_canny = DataLoader(train_dataset_canny, batch_size=32, shuffle=True)\n",
    "val_loader_canny = DataLoader(val_dataset_canny, batch_size=32, shuffle=False)\n",
    "test_loader_canny = DataLoader(test_dataset_canny, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weights and Biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login(\n",
    "    key=\"52cc20b894f4ec68c5e30b411f8f55148e7e54ec\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de Resnet-50 preentrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\richa\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\richa\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "# Cargamos el modelo preentrenado\n",
    "resnet50  = models.resnet50(pretrained=True)\n",
    "\n",
    "# Se modifica la capa final para adaptarla a 3 clases\n",
    "num_classes = 3\n",
    "num_ftrs = resnet50.fc.in_features\n",
    "resnet50.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "# Se congela el modelo para que no se actualicen los pesos de las capas preentrenadas\n",
    "for param in resnet50.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in resnet50.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Se mueve el modelo a la GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "resnet50 = resnet50.to(device)\n",
    "\n",
    "# Solo los parametros de la capa final se entrenan\n",
    "optimizer = torch.optim.Adam(resnet50.fc.parameters(), lr=0.001)\n",
    "\n",
    "# Se define la función de pérdida\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\richa\\OneDrive\\Desktop\\TEC\\IA-RedesConvolucionales\\wandb\\run-20241014_192019-g0p5srvb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/iaredescnncnn-instituto-tecnol-gico-de-costa-rica/Model-A/runs/g0p5srvb' target=\"_blank\">worldly-wave-23</a></strong> to <a href='https://wandb.ai/iaredescnncnn-instituto-tecnol-gico-de-costa-rica/Model-A' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/iaredescnncnn-instituto-tecnol-gico-de-costa-rica/Model-A' target=\"_blank\">https://wandb.ai/iaredescnncnn-instituto-tecnol-gico-de-costa-rica/Model-A</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/iaredescnncnn-instituto-tecnol-gico-de-costa-rica/Model-A/runs/g0p5srvb' target=\"_blank\">https://wandb.ai/iaredescnncnn-instituto-tecnol-gico-de-costa-rica/Model-A/runs/g0p5srvb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(project='Model-A')\n",
    "\n",
    "wandb.config={\n",
    "    'batch_size': 32,\n",
    "    'learning_rate': 0.001,\n",
    "    'epochs': 10,\n",
    "    'optimizer': 'Adam',\n",
    "}\n",
    "wandb.watch(resnet50, log='all', log_freq=10)\n",
    "\n",
    "def train_model(train_loader,val_loader,n_epochs,best_val_acc=0.0):\n",
    "    for epoch in range(n_epochs):\n",
    "        resnet50.train()\n",
    "        train_loss = 0.0 \n",
    "     \n",
    "        # Entrenamiento\n",
    "        for input,labels in train_loader: # Se recorren los datos de entrenamiento\n",
    "            inputs, labels = input.to(device), labels.to(device)\n",
    "            optimizer.zero_grad() # Se reinician los gradientes\n",
    "            outputs = resnet50(inputs) # Se obtiene la salida del modelo\n",
    "            loss = criterion(outputs, labels) # Se calcula la pérdida\n",
    " \n",
    "            loss.backward() # Se calculan los gradientes\n",
    "            optimizer.step() # Se actualizan los pesos\n",
    "\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            _,predicted = torch.max(outputs, 1)\n",
    "            corrects = torch.sum(predicted == labels.data)\n",
    "\n",
    "        train_loss = train_loss / len(train_loader.dataset)\n",
    "        train_acc = corrects.double() / len(train_loader.dataset)\n",
    "\n",
    "        #Validación\n",
    "        resnet50.eval()\n",
    "        val_loss = 0.0\n",
    "        val_corrects = 0\n",
    "        with torch.no_grad(): # No se calculan los gradientes en la validación\n",
    "            for input,labels in val_loader:\n",
    "                inputs, labels = input.to(device), labels.to(device)\n",
    "                outputs = resnet50(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "                _,predicted = torch.max(outputs, 1)\n",
    "                val_corrects += torch.sum(predicted == labels.data)\n",
    "\n",
    "            val_loss = val_loss/len(val_loader.dataset)\n",
    "            val_acc = val_corrects.double() / len(val_loader.dataset)\n",
    "\n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                torch.save(resnet50.state_dict(), 'best_model.pth')\n",
    "                print(f\"Mejor modelo guardado con accuracy: {best_val_acc}\")\n",
    "\n",
    "            wandb.log({\n",
    "                \"Epoch\": epoch,\n",
    "                \"Train Loss\": train_loss,\n",
    "                \"Train Acc\": train_acc,\n",
    "                \"Val Loss\": val_loss,\n",
    "                \"Val Acc\": val_acc,\n",
    "            })\n",
    "            print('Epoch: {} Train Loss: {:.4f} Train Acc: {:.4f} Val Loss: {:.4f} Val Acc: {:.4f}'.format(epoch, train_loss, train_acc, val_loss, val_acc))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Crudo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor modelo guardado con accuracy: 0.7837837837837838\n",
      "Epoch: 0 Train Loss: 0.3575 Train Acc: 0.0853 Val Loss: 0.4842 Val Acc: 0.7838\n",
      "Epoch: 1 Train Loss: 0.3850 Train Acc: 0.0664 Val Loss: 0.5950 Val Acc: 0.6757\n",
      "Mejor modelo guardado con accuracy: 0.8378378378378379\n",
      "Epoch: 2 Train Loss: 0.3313 Train Acc: 0.0900 Val Loss: 0.4133 Val Acc: 0.8378\n",
      "Mejor modelo guardado con accuracy: 0.8918918918918919\n",
      "Epoch: 3 Train Loss: 0.3215 Train Acc: 0.0758 Val Loss: 0.3105 Val Acc: 0.8919\n",
      "Mejor modelo guardado con accuracy: 0.945945945945946\n",
      "Epoch: 4 Train Loss: 0.2934 Train Acc: 0.0900 Val Loss: 0.3241 Val Acc: 0.9459\n",
      "Epoch: 5 Train Loss: 0.3430 Train Acc: 0.0569 Val Loss: 0.3119 Val Acc: 0.8919\n",
      "Mejor modelo guardado con accuracy: 0.972972972972973\n",
      "Epoch: 6 Train Loss: 0.3244 Train Acc: 0.0900 Val Loss: 0.2327 Val Acc: 0.9730\n",
      "Epoch: 7 Train Loss: 0.2680 Train Acc: 0.0853 Val Loss: 0.3382 Val Acc: 0.8378\n",
      "Epoch: 8 Train Loss: 0.2932 Train Acc: 0.0853 Val Loss: 0.2031 Val Acc: 0.9730\n",
      "Epoch: 9 Train Loss: 0.3114 Train Acc: 0.0900 Val Loss: 0.2423 Val Acc: 0.9189\n"
     ]
    }
   ],
   "source": [
    "train_model(train_loader, val_loader, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d458094448f142c584cece6c5cb8a4d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.251 MB of 0.251 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>Train Acc</td><td>▂▅▁▇▅▇█▂█▄</td></tr><tr><td>Train Loss</td><td>█▆▄▃▂▂▂▁▁▁</td></tr><tr><td>Val Acc</td><td>▃▂▁█▃▆▃▇▆▆</td></tr><tr><td>Val Loss</td><td>▇▇█▃▄▃▄▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>9</td></tr><tr><td>Train Acc</td><td>0.07109</td></tr><tr><td>Train Loss</td><td>0.40243</td></tr><tr><td>Val Acc</td><td>0.72973</td></tr><tr><td>Val Loss</td><td>0.5741</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">volcanic-elevator-19</strong> at: <a href='https://wandb.ai/iaredescnncnn-instituto-tecnol-gico-de-costa-rica/Model-A/runs/ymjkjbet' target=\"_blank\">https://wandb.ai/iaredescnncnn-instituto-tecnol-gico-de-costa-rica/Model-A/runs/ymjkjbet</a><br/> View project at: <a href='https://wandb.ai/iaredescnncnn-instituto-tecnol-gico-de-costa-rica/Model-A' target=\"_blank\">https://wandb.ai/iaredescnncnn-instituto-tecnol-gico-de-costa-rica/Model-A</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241014_182752-ymjkjbet\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset con filtro Bilateral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor modelo guardado con accuracy: 0.7567567567567568\n",
      "Epoch: 0 Train Loss: 0.3540 Train Acc: 0.0664 Val Loss: 0.4470 Val Acc: 0.7568\n",
      "Mejor modelo guardado con accuracy: 0.8648648648648649\n",
      "Epoch: 1 Train Loss: 0.3901 Train Acc: 0.0853 Val Loss: 0.4183 Val Acc: 0.8649\n",
      "Mejor modelo guardado con accuracy: 0.918918918918919\n",
      "Epoch: 2 Train Loss: 0.3238 Train Acc: 0.0806 Val Loss: 0.3219 Val Acc: 0.9189\n",
      "Epoch: 3 Train Loss: 0.3099 Train Acc: 0.0758 Val Loss: 0.3836 Val Acc: 0.8919\n",
      "Epoch: 4 Train Loss: 0.2582 Train Acc: 0.0853 Val Loss: 0.3967 Val Acc: 0.8378\n",
      "Epoch: 5 Train Loss: 0.3361 Train Acc: 0.0853 Val Loss: 0.2980 Val Acc: 0.9189\n",
      "Mejor modelo guardado con accuracy: 0.945945945945946\n",
      "Epoch: 6 Train Loss: 0.3330 Train Acc: 0.0900 Val Loss: 0.2353 Val Acc: 0.9459\n",
      "Epoch: 7 Train Loss: 0.2705 Train Acc: 0.0758 Val Loss: 0.3208 Val Acc: 0.8649\n",
      "Epoch: 8 Train Loss: 0.2582 Train Acc: 0.0900 Val Loss: 0.2489 Val Acc: 0.9459\n",
      "Epoch: 9 Train Loss: 0.3081 Train Acc: 0.0853 Val Loss: 0.2868 Val Acc: 0.9189\n"
     ]
    }
   ],
   "source": [
    "train_model(train_loader_bilateral, val_loader_bilateral, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cbaa8a51b40402a9f75aab7ee62c8da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.150 MB of 0.977 MB uploaded\\r'), FloatProgress(value=0.15347561684010336, max=1.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>Train Acc</td><td>▁▇▅▄▇▇█▄█▇</td></tr><tr><td>Train Loss</td><td>▆█▄▄▁▅▅▂▁▄</td></tr><tr><td>Val Acc</td><td>▁▅▇▆▄▇█▅█▇</td></tr><tr><td>Val Loss</td><td>█▇▄▆▆▃▁▄▁▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>9</td></tr><tr><td>Train Acc</td><td>0.08531</td></tr><tr><td>Train Loss</td><td>0.30809</td></tr><tr><td>Val Acc</td><td>0.91892</td></tr><tr><td>Val Loss</td><td>0.28679</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">kind-smoke-22</strong> at: <a href='https://wandb.ai/iaredescnncnn-instituto-tecnol-gico-de-costa-rica/Model-A/runs/h50wssbu' target=\"_blank\">https://wandb.ai/iaredescnncnn-instituto-tecnol-gico-de-costa-rica/Model-A/runs/h50wssbu</a><br/> View project at: <a href='https://wandb.ai/iaredescnncnn-instituto-tecnol-gico-de-costa-rica/Model-A' target=\"_blank\">https://wandb.ai/iaredescnncnn-instituto-tecnol-gico-de-costa-rica/Model-A</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241014_191912-h50wssbu\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset con filtro Canny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor modelo guardado con accuracy: 0.5135135135135136\n",
      "Epoch: 0 Train Loss: 0.9721 Train Acc: 0.0664 Val Loss: 1.0962 Val Acc: 0.5135\n",
      "Mejor modelo guardado con accuracy: 0.5945945945945946\n",
      "Epoch: 1 Train Loss: 0.8117 Train Acc: 0.0569 Val Loss: 0.8158 Val Acc: 0.5946\n",
      "Mejor modelo guardado con accuracy: 0.7027027027027027\n",
      "Epoch: 2 Train Loss: 0.7568 Train Acc: 0.0521 Val Loss: 0.7588 Val Acc: 0.7027\n",
      "Epoch: 3 Train Loss: 0.6020 Train Acc: 0.0711 Val Loss: 0.8532 Val Acc: 0.5676\n",
      "Epoch: 4 Train Loss: 0.6283 Train Acc: 0.0711 Val Loss: 0.8589 Val Acc: 0.6486\n",
      "Epoch: 5 Train Loss: 0.5582 Train Acc: 0.0664 Val Loss: 0.8215 Val Acc: 0.5946\n",
      "Epoch: 6 Train Loss: 0.5792 Train Acc: 0.0616 Val Loss: 0.8919 Val Acc: 0.6757\n",
      "Epoch: 7 Train Loss: 0.5916 Train Acc: 0.0711 Val Loss: 0.9229 Val Acc: 0.5946\n",
      "Epoch: 8 Train Loss: 0.6061 Train Acc: 0.0521 Val Loss: 0.7909 Val Acc: 0.6216\n",
      "Epoch: 9 Train Loss: 0.5334 Train Acc: 0.0521 Val Loss: 0.8524 Val Acc: 0.6757\n"
     ]
    }
   ],
   "source": [
    "train_model(train_loader_canny, val_loader_canny, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\richa\\AppData\\Local\\Temp\\ipykernel_5956\\3012626626.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  resnet50.load_state_dict(torch.load('best_model.pth'))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Se carga el modelo\n",
    "resnet50.load_state_dict(torch.load('best_model.pth'))\n",
    "\n",
    "# Se evalua el modelo\n",
    "resnet50.eval()\n",
    "\n",
    "def test_model(test_loader):\n",
    "    test_corrects = 0\n",
    "    with torch.no_grad():\n",
    "        for input,labels in test_loader:\n",
    "            inputs, labels = input.to(device), labels.to(device)\n",
    "            outputs = resnet50(inputs)\n",
    "            _,predicted = torch.max(outputs, 1)\n",
    "            test_corrects += torch.sum(predicted == labels.data)\n",
    "\n",
    "        test_acc = test_corrects.double() / len(test_loader.dataset)\n",
    "    \n",
    "        print('Test Accuracy: {:.4f}'.format(test_acc))   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Crudo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.3939\n"
     ]
    }
   ],
   "source": [
    "test_model(test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
