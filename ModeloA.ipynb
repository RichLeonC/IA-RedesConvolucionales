{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo A para clasificación de imagenes\n",
    "\n",
    "#### Jeffrey Daniel Leiva Cascante 2021016720\n",
    "#### Richard Osvaldo León Chinchilla 2019003759\n",
    "\n",
    "## Inicialización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), # Resnet es de 224x224\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5]),\n",
    "    transforms.RandomRotation(20),  # Rotación aleatoria\n",
    "    transforms.RandomHorizontalFlip(),  # Inversión horizontal aleatoria\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),  # Variación de brillo y contraste\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5]),\n",
    "    \n",
    "])\n",
    "\n",
    "# Cargamos el dataset de entrenamiento para cada dataset\n",
    "train_dataset = datasets.ImageFolder(root='./Covid19-dataset/train', transform=transform)\n",
    "train_dataset_bilateral = datasets.ImageFolder(root='./Covid19-dataset-bilateral/train', transform=transform)\n",
    "train_dataset_canny = datasets.ImageFolder(root='./Covid19-dataset-canny/train', transform=transform)\n",
    "\n",
    "# Cargamos el dataset de test para cada dataset\n",
    "test_dataset = datasets.ImageFolder(root='./Covid19-dataset/test', transform=transform_test)\n",
    "test_dataset_bilateral = datasets.ImageFolder(root='./Covid19-dataset-bilateral/test', transform=transform_test)\n",
    "test_dataset_canny = datasets.ImageFolder(root='./Covid19-dataset-canny/test', transform=transform_test)\n",
    "\n",
    "val_percent = 0.15 # Porcentaje de imágenes que se usarán para validación\n",
    "\n",
    "# Calculamos el tamaño de los conjuntos de entrenamiento y validación\n",
    "val_size = int(val_percent * len(train_dataset))\n",
    "train_size = len(train_dataset) - val_size\n",
    "\n",
    "val_size_bilateral = int(val_percent * len(train_dataset_bilateral))\n",
    "train_size_bilateral = len(train_dataset_bilateral) - val_size_bilateral\n",
    "\n",
    "val_size_canny = int(val_percent * len(train_dataset_canny))\n",
    "train_size_canny = len(train_dataset_canny) - val_size_canny\n",
    "\n",
    "# Se divide el dataset en dos\n",
    "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
    "train_dataset_bilateral, val_dataset_bilateral = random_split(train_dataset_bilateral, [train_size_bilateral, val_size_bilateral])\n",
    "train_dataset_canny, val_dataset_canny = random_split(train_dataset_canny, [train_size_canny, val_size_canny])\n",
    "\n",
    "# Aplicamos el transformador de testing a los conjuntos de validación\n",
    "val_dataset.dataset.transform = transform_test\n",
    "val_dataset_bilateral.dataset.transform = transform_test\n",
    "val_dataset_canny.dataset.transform = transform_test\n",
    "\n",
    "# Creamos los dataloaders para cada dataset\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "train_loader_bilateral = DataLoader(train_dataset_bilateral, batch_size=32, shuffle=True)\n",
    "val_loader_bilateral = DataLoader(val_dataset_bilateral, batch_size=32, shuffle=False)\n",
    "test_loader_bilateral = DataLoader(test_dataset_bilateral, batch_size=32, shuffle=False)\n",
    "\n",
    "train_loader_canny = DataLoader(train_dataset_canny, batch_size=32, shuffle=True)\n",
    "val_loader_canny = DataLoader(val_dataset_canny, batch_size=32, shuffle=False)\n",
    "test_loader_canny = DataLoader(test_dataset_canny, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weights and Biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "wandb: Currently logged in as: r29leonc (iaredescnncnn-instituto-tecnol-gico-de-costa-rica). Use `wandb login --relogin` to force relogin\n",
      "wandb: WARNING If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "wandb: WARNING Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "wandb: Appending key for api.wandb.ai to your netrc file: C:\\Users\\richa\\_netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login(\n",
    "    key=\"52cc20b894f4ec68c5e30b411f8f55148e7e54ec\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de Resnet-50 preentrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\richa\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\richa\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "# Cargamos el modelo preentrenado\n",
    "resnet50  = models.resnet50(pretrained=True)\n",
    "\n",
    "# Se modifica la capa final para adaptarla a 3 clases\n",
    "num_classes = 3\n",
    "num_ftrs = resnet50.fc.in_features\n",
    "resnet50.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "# Se congela el modelo para que no se actualicen los pesos de las capas preentrenadas\n",
    "for param in resnet50.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in resnet50.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Se mueve el modelo a la GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "resnet50 = resnet50.to(device)\n",
    "\n",
    "# Solo los parametros de la capa final se entrenan\n",
    "optimizer = torch.optim.Adam(resnet50.fc.parameters(), lr=0.001)\n",
    "\n",
    "# Se define la función de pérdida\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:gtc5vdxt) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "359955b0da67421f8fa3734bec56d352",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.008 MB of 0.008 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">distinctive-bird-54</strong> at: <a href='https://wandb.ai/iaredescnncnn-instituto-tecnol-gico-de-costa-rica/Model-A/runs/gtc5vdxt' target=\"_blank\">https://wandb.ai/iaredescnncnn-instituto-tecnol-gico-de-costa-rica/Model-A/runs/gtc5vdxt</a><br/> View project at: <a href='https://wandb.ai/iaredescnncnn-instituto-tecnol-gico-de-costa-rica/Model-A' target=\"_blank\">https://wandb.ai/iaredescnncnn-instituto-tecnol-gico-de-costa-rica/Model-A</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241015_202045-gtc5vdxt\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:gtc5vdxt). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\richa\\OneDrive\\Desktop\\TEC\\IA-RedesConvolucionales\\wandb\\run-20241015_202327-s78iur7z</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/iaredescnncnn-instituto-tecnol-gico-de-costa-rica/Model-A/runs/s78iur7z' target=\"_blank\">vocal-cloud-55</a></strong> to <a href='https://wandb.ai/iaredescnncnn-instituto-tecnol-gico-de-costa-rica/Model-A' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/iaredescnncnn-instituto-tecnol-gico-de-costa-rica/Model-A' target=\"_blank\">https://wandb.ai/iaredescnncnn-instituto-tecnol-gico-de-costa-rica/Model-A</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/iaredescnncnn-instituto-tecnol-gico-de-costa-rica/Model-A/runs/s78iur7z' target=\"_blank\">https://wandb.ai/iaredescnncnn-instituto-tecnol-gico-de-costa-rica/Model-A/runs/s78iur7z</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(project='Model-A')\n",
    "\n",
    "wandb.config={\n",
    "    'batch_size': 32,\n",
    "    'learning_rate': 0.001,\n",
    "    'epochs': 10,\n",
    "    'optimizer': 'Adam',\n",
    "}\n",
    "wandb.watch(resnet50, log='all', log_freq=10)\n",
    "\n",
    "def train_model(train_loader,val_loader,n_epochs,best_val_acc=0.0,name_model='best_model.pth'):\n",
    "    for epoch in range(n_epochs):\n",
    "        resnet50.train()\n",
    "        train_loss = 0.0 \n",
    "     \n",
    "        # Entrenamiento\n",
    "        for input,labels in train_loader: # Se recorren los datos de entrenamiento\n",
    "            inputs, labels = input.to(device), labels.to(device)\n",
    "            optimizer.zero_grad() # Se reinician los gradientes\n",
    "            outputs = resnet50(inputs) # Se obtiene la salida del modelo\n",
    "            loss = criterion(outputs, labels) # Se calcula la pérdida\n",
    " \n",
    "            loss.backward() # Se calculan los gradientes\n",
    "            optimizer.step() # Se actualizan los pesos\n",
    "\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            _,predicted = torch.max(outputs, 1)\n",
    "            corrects = torch.sum(predicted == labels.data)\n",
    "\n",
    "        train_loss = train_loss / len(train_loader.dataset)\n",
    "        train_acc = corrects.double() / len(train_loader.dataset)\n",
    "\n",
    "        #Validación\n",
    "        resnet50.eval()\n",
    "        val_loss = 0.0\n",
    "        val_corrects = 0\n",
    "        with torch.no_grad(): # No se calculan los gradientes en la validación\n",
    "            for inputs,labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = resnet50(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "                _,predicted = torch.max(outputs, 1)\n",
    "                val_corrects += torch.sum(predicted == labels.data)\n",
    "\n",
    "            val_loss = val_loss/len(val_loader.dataset)\n",
    "            val_acc = val_corrects.double() / len(val_loader.dataset)\n",
    "\n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                torch.save(resnet50.state_dict(), name_model)\n",
    "                print(f\"Mejor modelo guardado con accuracy: {best_val_acc}\")\n",
    "\n",
    "            wandb.log({\n",
    "                \"Epoch\": epoch,\n",
    "                \"Train Loss\": train_loss,\n",
    "                \"Train Acc\": train_acc,\n",
    "                \"Val Loss\": val_loss,\n",
    "                \"Val Acc\": val_acc,\n",
    "            })\n",
    "            print('Epoch: {} Train Loss: {:.4f} Train Acc: {:.4f} Val Loss: {:.4f} Val Acc: {:.4f}'.format(epoch, train_loss, train_acc, val_loss, val_acc))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Crudo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor modelo guardado con accuracy: 0.7297297297297298\n",
      "Epoch: 0 Train Loss: 0.6105 Train Acc: 0.0853 Val Loss: 0.6667 Val Acc: 0.7297\n",
      "Mejor modelo guardado con accuracy: 0.8648648648648649\n",
      "Epoch: 1 Train Loss: 0.4756 Train Acc: 0.0711 Val Loss: 0.5157 Val Acc: 0.8649\n",
      "Epoch: 2 Train Loss: 0.3873 Train Acc: 0.0758 Val Loss: 0.5508 Val Acc: 0.8108\n",
      "Epoch: 3 Train Loss: 0.3329 Train Acc: 0.0664 Val Loss: 0.4999 Val Acc: 0.8108\n",
      "Epoch: 4 Train Loss: 0.2987 Train Acc: 0.0853 Val Loss: 0.4478 Val Acc: 0.8649\n",
      "Epoch: 5 Train Loss: 0.2916 Train Acc: 0.0900 Val Loss: 0.4374 Val Acc: 0.8108\n",
      "Mejor modelo guardado con accuracy: 0.8918918918918919\n",
      "Epoch: 6 Train Loss: 0.2263 Train Acc: 0.0900 Val Loss: 0.3493 Val Acc: 0.8919\n",
      "Mejor modelo guardado con accuracy: 0.918918918918919\n",
      "Epoch: 7 Train Loss: 0.2216 Train Acc: 0.0806 Val Loss: 0.3012 Val Acc: 0.9189\n",
      "Epoch: 8 Train Loss: 0.2474 Train Acc: 0.0806 Val Loss: 0.3229 Val Acc: 0.9189\n",
      "Epoch: 9 Train Loss: 0.1898 Train Acc: 0.0806 Val Loss: 0.2527 Val Acc: 0.9189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Fatal error while uploading data. Some run data will not be synced, but it will still be written to disk. Use `wandb sync` at the end of the run to try uploading.\n"
     ]
    }
   ],
   "source": [
    "train_model(train_loader, val_loader, 20,name_model='ModelA_raw.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc94d67559144ef183d06f9dd4513966",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.884 MB of 0.975 MB uploaded\\r'), FloatProgress(value=0.9065445141357008, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>Train Acc</td><td>▅▅▁▅▃█▃▁█▆</td></tr><tr><td>Train Loss</td><td>▇█▆▅▆▂▄▃▁▂</td></tr><tr><td>Val Acc</td><td>▆▁▁▇█▇████</td></tr><tr><td>Val Loss</td><td>▅██▂▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>9</td></tr><tr><td>Train Acc</td><td>0.08531</td></tr><tr><td>Train Loss</td><td>0.13813</td></tr><tr><td>Val Acc</td><td>1</td></tr><tr><td>Val Loss</td><td>0.06291</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">frosty-shadow-37</strong> at: <a href='https://wandb.ai/iaredescnncnn-instituto-tecnol-gico-de-costa-rica/Model-A/runs/rr3tt18x' target=\"_blank\">https://wandb.ai/iaredescnncnn-instituto-tecnol-gico-de-costa-rica/Model-A/runs/rr3tt18x</a><br/> View project at: <a href='https://wandb.ai/iaredescnncnn-instituto-tecnol-gico-de-costa-rica/Model-A' target=\"_blank\">https://wandb.ai/iaredescnncnn-instituto-tecnol-gico-de-costa-rica/Model-A</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241015_182757-rr3tt18x\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset con filtro Bilateral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor modelo guardado con accuracy: 0.7567567567567568\n",
      "Epoch: 0 Train Loss: 0.2362 Train Acc: 0.0900 Val Loss: 0.5420 Val Acc: 0.7568\n",
      "Mejor modelo guardado con accuracy: 0.918918918918919\n",
      "Epoch: 1 Train Loss: 0.2197 Train Acc: 0.0806 Val Loss: 0.3092 Val Acc: 0.9189\n",
      "Mejor modelo guardado con accuracy: 0.972972972972973\n",
      "Epoch: 2 Train Loss: 0.1994 Train Acc: 0.0900 Val Loss: 0.2191 Val Acc: 0.9730\n",
      "Epoch: 3 Train Loss: 0.1733 Train Acc: 0.0853 Val Loss: 0.2829 Val Acc: 0.8919\n",
      "Epoch: 4 Train Loss: 0.1874 Train Acc: 0.0900 Val Loss: 0.2063 Val Acc: 0.9459\n",
      "Epoch: 5 Train Loss: 0.1453 Train Acc: 0.0900 Val Loss: 0.2203 Val Acc: 0.9459\n",
      "Epoch: 6 Train Loss: 0.1475 Train Acc: 0.0900 Val Loss: 0.2936 Val Acc: 0.8649\n",
      "Epoch: 7 Train Loss: 0.1239 Train Acc: 0.0853 Val Loss: 0.2223 Val Acc: 0.9459\n",
      "Epoch: 8 Train Loss: 0.1269 Train Acc: 0.0900 Val Loss: 0.2379 Val Acc: 0.8919\n",
      "Epoch: 9 Train Loss: 0.1237 Train Acc: 0.0900 Val Loss: 0.2717 Val Acc: 0.8919\n",
      "Epoch: 10 Train Loss: 0.1140 Train Acc: 0.0900 Val Loss: 0.2342 Val Acc: 0.9459\n",
      "Epoch: 11 Train Loss: 0.1604 Train Acc: 0.0664 Val Loss: 0.2608 Val Acc: 0.8919\n",
      "Epoch: 12 Train Loss: 0.1074 Train Acc: 0.0900 Val Loss: 0.2508 Val Acc: 0.9459\n",
      "Epoch: 13 Train Loss: 0.1073 Train Acc: 0.0900 Val Loss: 0.2159 Val Acc: 0.9189\n",
      "Epoch: 14 Train Loss: 0.1275 Train Acc: 0.0806 Val Loss: 0.2938 Val Acc: 0.8649\n",
      "Epoch: 15 Train Loss: 0.0929 Train Acc: 0.0900 Val Loss: 0.2496 Val Acc: 0.9459\n",
      "Epoch: 16 Train Loss: 0.1075 Train Acc: 0.0900 Val Loss: 0.2223 Val Acc: 0.9189\n",
      "Epoch: 17 Train Loss: 0.0874 Train Acc: 0.0900 Val Loss: 0.3265 Val Acc: 0.8378\n",
      "Epoch: 18 Train Loss: 0.1066 Train Acc: 0.0853 Val Loss: 0.2622 Val Acc: 0.8919\n",
      "Epoch: 19 Train Loss: 0.0878 Train Acc: 0.0900 Val Loss: 0.2009 Val Acc: 0.9189\n",
      "Epoch: 20 Train Loss: 0.0691 Train Acc: 0.0900 Val Loss: 0.2914 Val Acc: 0.8649\n",
      "Epoch: 21 Train Loss: 0.0867 Train Acc: 0.0900 Val Loss: 0.2741 Val Acc: 0.8919\n",
      "Epoch: 22 Train Loss: 0.0914 Train Acc: 0.0806 Val Loss: 0.2358 Val Acc: 0.8649\n",
      "Epoch: 23 Train Loss: 0.0697 Train Acc: 0.0900 Val Loss: 0.2804 Val Acc: 0.8649\n",
      "Epoch: 24 Train Loss: 0.0884 Train Acc: 0.0900 Val Loss: 0.2370 Val Acc: 0.8649\n",
      "Epoch: 25 Train Loss: 0.0859 Train Acc: 0.0900 Val Loss: 0.2199 Val Acc: 0.9189\n",
      "Epoch: 26 Train Loss: 0.0832 Train Acc: 0.0900 Val Loss: 0.2636 Val Acc: 0.8919\n",
      "Epoch: 27 Train Loss: 0.0709 Train Acc: 0.0900 Val Loss: 0.2441 Val Acc: 0.9459\n",
      "Epoch: 28 Train Loss: 0.0757 Train Acc: 0.0853 Val Loss: 0.2656 Val Acc: 0.8649\n",
      "Epoch: 29 Train Loss: 0.0653 Train Acc: 0.0900 Val Loss: 0.2865 Val Acc: 0.8649\n"
     ]
    }
   ],
   "source": [
    "train_model(train_loader_bilateral, val_loader_bilateral, 30, name_model='ModelA_bilateral.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset con filtro Canny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor modelo guardado con accuracy: 0.35135135135135137\n",
      "Epoch: 0 Train Loss: 0.3801 Train Acc: 0.0806 Val Loss: 1.9319 Val Acc: 0.3514\n",
      "Mejor modelo guardado con accuracy: 0.7567567567567568\n",
      "Epoch: 1 Train Loss: 0.3984 Train Acc: 0.0616 Val Loss: 0.6079 Val Acc: 0.7568\n",
      "Mejor modelo guardado con accuracy: 0.7837837837837838\n",
      "Epoch: 2 Train Loss: 0.3367 Train Acc: 0.0806 Val Loss: 0.3767 Val Acc: 0.7838\n",
      "Mejor modelo guardado con accuracy: 0.8648648648648649\n",
      "Epoch: 3 Train Loss: 0.3074 Train Acc: 0.0853 Val Loss: 0.3154 Val Acc: 0.8649\n",
      "Mejor modelo guardado con accuracy: 0.918918918918919\n",
      "Epoch: 4 Train Loss: 0.2998 Train Acc: 0.0711 Val Loss: 0.2348 Val Acc: 0.9189\n",
      "Epoch: 5 Train Loss: 0.2850 Train Acc: 0.0616 Val Loss: 0.3023 Val Acc: 0.8649\n",
      "Epoch: 6 Train Loss: 0.3363 Train Acc: 0.0806 Val Loss: 0.2446 Val Acc: 0.8919\n",
      "Epoch: 7 Train Loss: 0.2191 Train Acc: 0.0853 Val Loss: 0.3051 Val Acc: 0.8649\n",
      "Epoch: 8 Train Loss: 0.2436 Train Acc: 0.0853 Val Loss: 0.2387 Val Acc: 0.8649\n",
      "Epoch: 9 Train Loss: 0.2016 Train Acc: 0.0853 Val Loss: 0.2588 Val Acc: 0.8919\n",
      "Epoch: 10 Train Loss: 0.1933 Train Acc: 0.0900 Val Loss: 0.2534 Val Acc: 0.8649\n",
      "Epoch: 11 Train Loss: 0.1944 Train Acc: 0.0853 Val Loss: 0.2518 Val Acc: 0.8919\n",
      "Epoch: 12 Train Loss: 0.1952 Train Acc: 0.0853 Val Loss: 0.2245 Val Acc: 0.8919\n",
      "Epoch: 13 Train Loss: 0.2124 Train Acc: 0.0806 Val Loss: 0.2481 Val Acc: 0.8919\n",
      "Epoch: 14 Train Loss: 0.1813 Train Acc: 0.0806 Val Loss: 0.2186 Val Acc: 0.8649\n",
      "Epoch: 15 Train Loss: 0.2157 Train Acc: 0.0758 Val Loss: 0.2525 Val Acc: 0.8919\n",
      "Epoch: 16 Train Loss: 0.1614 Train Acc: 0.0853 Val Loss: 0.2817 Val Acc: 0.8649\n",
      "Epoch: 17 Train Loss: 0.1718 Train Acc: 0.0900 Val Loss: 0.2913 Val Acc: 0.8919\n",
      "Epoch: 18 Train Loss: 0.1527 Train Acc: 0.0900 Val Loss: 0.2113 Val Acc: 0.9189\n",
      "Epoch: 19 Train Loss: 0.1547 Train Acc: 0.0853 Val Loss: 0.2315 Val Acc: 0.8919\n",
      "Epoch: 20 Train Loss: 0.1672 Train Acc: 0.0806 Val Loss: 0.2653 Val Acc: 0.8919\n",
      "Epoch: 21 Train Loss: 0.1276 Train Acc: 0.0806 Val Loss: 0.2232 Val Acc: 0.8919\n",
      "Epoch: 22 Train Loss: 0.1478 Train Acc: 0.0900 Val Loss: 0.2187 Val Acc: 0.9189\n",
      "Epoch: 23 Train Loss: 0.1253 Train Acc: 0.0853 Val Loss: 0.2534 Val Acc: 0.8919\n",
      "Epoch: 24 Train Loss: 0.1275 Train Acc: 0.0900 Val Loss: 0.2084 Val Acc: 0.8919\n",
      "Epoch: 25 Train Loss: 0.1669 Train Acc: 0.0900 Val Loss: 0.2312 Val Acc: 0.8919\n",
      "Epoch: 26 Train Loss: 0.1325 Train Acc: 0.0758 Val Loss: 0.2267 Val Acc: 0.9189\n",
      "Epoch: 27 Train Loss: 0.1525 Train Acc: 0.0806 Val Loss: 0.2496 Val Acc: 0.8919\n",
      "Epoch: 28 Train Loss: 0.1438 Train Acc: 0.0758 Val Loss: 0.2635 Val Acc: 0.9189\n",
      "Epoch: 29 Train Loss: 0.1374 Train Acc: 0.0806 Val Loss: 0.2377 Val Acc: 0.8919\n"
     ]
    }
   ],
   "source": [
    "train_model(train_loader_canny, val_loader_canny, 30, name_model='ModelA_canny.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b88bd243b42a486b91a48e7b5c2e881a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.336 MB of 1.699 MB uploaded\\r'), FloatProgress(value=0.19770207578704915, max=1.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>Train Acc</td><td>▆▁▆▇▃▁▆▇▇▇█▇▇▆▆▅▇██▇▆▆█▇██▅▆▅▆</td></tr><tr><td>Train Loss</td><td>██▆▆▅▅▆▃▄▃▃▃▃▃▂▃▂▂▂▂▂▁▂▁▁▂▁▂▁▁</td></tr><tr><td>Val Acc</td><td>▁▆▆▇█▇█▇▇█▇███▇█▇█████████████</td></tr><tr><td>Val Loss</td><td>█▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>29</td></tr><tr><td>Train Acc</td><td>0.08057</td></tr><tr><td>Train Loss</td><td>0.13737</td></tr><tr><td>Val Acc</td><td>0.89189</td></tr><tr><td>Val Loss</td><td>0.23773</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">rich-gorge-40</strong> at: <a href='https://wandb.ai/iaredescnncnn-instituto-tecnol-gico-de-costa-rica/Model-A/runs/ia8es2d1' target=\"_blank\">https://wandb.ai/iaredescnncnn-instituto-tecnol-gico-de-costa-rica/Model-A/runs/ia8es2d1</a><br/> View project at: <a href='https://wandb.ai/iaredescnncnn-instituto-tecnol-gico-de-costa-rica/Model-A' target=\"_blank\">https://wandb.ai/iaredescnncnn-instituto-tecnol-gico-de-costa-rica/Model-A</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241015_183407-ia8es2d1\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_model(test_loader_p,name_model):\n",
    "    # Se carga el modelo\n",
    "    resnet50.load_state_dict(torch.load(name_model))\n",
    "    resnet50.eval()\n",
    "    test_corrects = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs,labels in test_loader_p:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = resnet50(inputs)\n",
    "            _,predicted = torch.max(outputs, 1)\n",
    "            test_corrects += torch.sum(predicted == labels.data)\n",
    "\n",
    "        test_acc = test_corrects.double() / len(test_loader.dataset)\n",
    "    \n",
    "        print('Test Accuracy: {:.4f}'.format(test_acc))   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Crudo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\richa\\AppData\\Local\\Temp\\ipykernel_7352\\2173458215.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  resnet50.load_state_dict(torch.load(\"ModelA_raw.pth\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8939\n"
     ]
    }
   ],
   "source": [
    "test_model(test_loader, name_model='ModelA_raw.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bilateral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\richa\\AppData\\Local\\Temp\\ipykernel_7352\\2173458215.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  resnet50.load_state_dict(torch.load(\"ModelA_raw.pth\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.6212\n"
     ]
    }
   ],
   "source": [
    "test_model(test_loader_bilateral, name_model='ModelA_bilateral.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Canny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\richa\\AppData\\Local\\Temp\\ipykernel_7352\\2173458215.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  resnet50.load_state_dict(torch.load(\"ModelA_raw.pth\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.5455\n"
     ]
    }
   ],
   "source": [
    "test_model(test_loader_canny, name_model='ModelA_canny.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
