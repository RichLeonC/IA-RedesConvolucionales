{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo A para clasificación de imagenes\n",
    "\n",
    "#### Jeffrey Daniel Leiva Cascante 2021016720\n",
    "#### Richard Osvaldo León Chinchilla 2019003759\n",
    "\n",
    "## Inicialización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), # Resnet es de 224x224\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5]),\n",
    "    transforms.RandomRotation(20),  # Rotación aleatoria\n",
    "    transforms.RandomHorizontalFlip(),  # Inversión horizontal aleatoria\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),  # Variación de brillo y contraste\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5]),\n",
    "    \n",
    "])\n",
    "\n",
    "# Cargamos el dataset de entrenamiento para cada dataset\n",
    "train_dataset = datasets.ImageFolder(root='./Covid19-dataset/train', transform=transform)\n",
    "train_dataset_bilateral = datasets.ImageFolder(root='./Covid19-dataset-bilateral/train', transform=transform)\n",
    "train_dataset_canny = datasets.ImageFolder(root='./Covid19-dataset-canny/train', transform=transform)\n",
    "\n",
    "# Cargamos el dataset de test para cada dataset\n",
    "test_dataset = datasets.ImageFolder(root='./Covid19-dataset/test', transform=transform_test)\n",
    "test_dataset_bilateral = datasets.ImageFolder(root='./Covid19-dataset-bilateral/test', transform=transform_test)\n",
    "test_dataset_canny = datasets.ImageFolder(root='./Covid19-dataset-canny/test', transform=transform_test)\n",
    "\n",
    "val_percent = 0.15 # Porcentaje de imágenes que se usarán para validación\n",
    "\n",
    "# Calculamos el tamaño de los conjuntos de entrenamiento y validación\n",
    "val_size = int(val_percent * len(train_dataset))\n",
    "train_size = len(train_dataset) - val_size\n",
    "\n",
    "val_size_bilateral = int(val_percent * len(train_dataset_bilateral))\n",
    "train_size_bilateral = len(train_dataset_bilateral) - val_size_bilateral\n",
    "\n",
    "val_size_canny = int(val_percent * len(train_dataset_canny))\n",
    "train_size_canny = len(train_dataset_canny) - val_size_canny\n",
    "\n",
    "# Se divide el dataset en dos\n",
    "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
    "train_dataset_bilateral, val_dataset_bilateral = random_split(train_dataset_bilateral, [train_size_bilateral, val_size_bilateral])\n",
    "train_dataset_canny, val_dataset_canny = random_split(train_dataset_canny, [train_size_canny, val_size_canny])\n",
    "\n",
    "# Aplicamos el transformador de testing a los conjuntos de validación\n",
    "val_dataset.dataset.transform = transform_test\n",
    "val_dataset_bilateral.dataset.transform = transform_test\n",
    "val_dataset_canny.dataset.transform = transform_test\n",
    "\n",
    "# Creamos los dataloaders para cada dataset\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "train_loader_bilateral = DataLoader(train_dataset_bilateral, batch_size=32, shuffle=True)\n",
    "val_loader_bilateral = DataLoader(val_dataset_bilateral, batch_size=32, shuffle=False)\n",
    "test_loader_bilateral = DataLoader(test_dataset_bilateral, batch_size=32, shuffle=False)\n",
    "\n",
    "train_loader_canny = DataLoader(train_dataset_canny, batch_size=32, shuffle=True)\n",
    "val_loader_canny = DataLoader(val_dataset_canny, batch_size=32, shuffle=False)\n",
    "test_loader_canny = DataLoader(test_dataset_canny, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weights and Biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "wandb: WARNING Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "wandb: Appending key for api.wandb.ai to your netrc file: C:\\Users\\richa\\_netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login(\n",
    "    key=\"52cc20b894f4ec68c5e30b411f8f55148e7e54ec\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de Resnet-50 preentrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\richa\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\richa\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "# Cargamos el modelo preentrenado\n",
    "resnet50  = models.resnet50(pretrained=True)\n",
    "\n",
    "# Se modifica la capa final para adaptarla a 3 clases\n",
    "num_classes = 3\n",
    "num_ftrs = resnet50.fc.in_features\n",
    "resnet50.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "# Se congela el modelo para que no se actualicen los pesos de las capas preentrenadas\n",
    "for param in resnet50.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in resnet50.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Se mueve el modelo a la GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "resnet50 = resnet50.to(device)\n",
    "\n",
    "# Solo los parametros de la capa final se entrenan\n",
    "optimizer = torch.optim.Adam(resnet50.fc.parameters(), lr=0.001)\n",
    "\n",
    "# Se define la función de pérdida\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:ucqsrmqn) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fda64af8f20640728b8033ab0a0f1175",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.493 MB of 0.493 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▃▆█</td></tr><tr><td>Train Acc</td><td>███▁</td></tr><tr><td>Train Loss</td><td>█▂▁▃</td></tr><tr><td>Val Acc</td><td>▁▁▁▁</td></tr><tr><td>Val Loss</td><td>▁▃█▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>3</td></tr><tr><td>Train Acc</td><td>0.07583</td></tr><tr><td>Train Loss</td><td>0.33451</td></tr><tr><td>Val Acc</td><td>0.39394</td></tr><tr><td>Val Loss</td><td>7.30032</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">prime-glitter-31</strong> at: <a href='https://wandb.ai/iaredescnncnn-instituto-tecnol-gico-de-costa-rica/Model-A/runs/ucqsrmqn' target=\"_blank\">https://wandb.ai/iaredescnncnn-instituto-tecnol-gico-de-costa-rica/Model-A/runs/ucqsrmqn</a><br/> View project at: <a href='https://wandb.ai/iaredescnncnn-instituto-tecnol-gico-de-costa-rica/Model-A' target=\"_blank\">https://wandb.ai/iaredescnncnn-instituto-tecnol-gico-de-costa-rica/Model-A</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241014_221433-ucqsrmqn\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:ucqsrmqn). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\richa\\OneDrive\\Desktop\\TEC\\IA-RedesConvolucionales\\wandb\\run-20241014_221829-9ty2h13g</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/iaredescnncnn-instituto-tecnol-gico-de-costa-rica/Model-A/runs/9ty2h13g' target=\"_blank\">crimson-thunder-32</a></strong> to <a href='https://wandb.ai/iaredescnncnn-instituto-tecnol-gico-de-costa-rica/Model-A' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/iaredescnncnn-instituto-tecnol-gico-de-costa-rica/Model-A' target=\"_blank\">https://wandb.ai/iaredescnncnn-instituto-tecnol-gico-de-costa-rica/Model-A</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/iaredescnncnn-instituto-tecnol-gico-de-costa-rica/Model-A/runs/9ty2h13g' target=\"_blank\">https://wandb.ai/iaredescnncnn-instituto-tecnol-gico-de-costa-rica/Model-A/runs/9ty2h13g</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(project='Model-A')\n",
    "\n",
    "wandb.config={\n",
    "    'batch_size': 32,\n",
    "    'learning_rate': 0.001,\n",
    "    'epochs': 10,\n",
    "    'optimizer': 'Adam',\n",
    "}\n",
    "wandb.watch(resnet50, log='all', log_freq=10)\n",
    "\n",
    "def train_model(train_loader,val_loader,n_epochs,best_val_acc=0.0):\n",
    "    for epoch in range(n_epochs):\n",
    "        resnet50.train()\n",
    "        train_loss = 0.0 \n",
    "     \n",
    "        # Entrenamiento\n",
    "        for input,labels in train_loader: # Se recorren los datos de entrenamiento\n",
    "            inputs, labels = input.to(device), labels.to(device)\n",
    "            optimizer.zero_grad() # Se reinician los gradientes\n",
    "            outputs = resnet50(inputs) # Se obtiene la salida del modelo\n",
    "            loss = criterion(outputs, labels) # Se calcula la pérdida\n",
    " \n",
    "            loss.backward() # Se calculan los gradientes\n",
    "            optimizer.step() # Se actualizan los pesos\n",
    "\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            _,predicted = torch.max(outputs, 1)\n",
    "            corrects = torch.sum(predicted == labels.data)\n",
    "\n",
    "        train_loss = train_loss / len(train_loader.dataset)\n",
    "        train_acc = corrects.double() / len(train_loader.dataset)\n",
    "\n",
    "        #Validación\n",
    "        resnet50.eval()\n",
    "        val_loss = 0.0\n",
    "        val_corrects = 0\n",
    "        with torch.no_grad(): # No se calculan los gradientes en la validación\n",
    "            for inputs,labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = resnet50(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "                _,predicted = torch.max(outputs, 1)\n",
    "                val_corrects += torch.sum(predicted == labels.data)\n",
    "\n",
    "            val_loss = val_loss/len(val_loader.dataset)\n",
    "            val_acc = val_corrects.double() / len(val_loader.dataset)\n",
    "\n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                torch.save(resnet50.state_dict(), 'best_model.pth')\n",
    "                print(f\"Mejor modelo guardado con accuracy: {best_val_acc}\")\n",
    "\n",
    "            wandb.log({\n",
    "                \"Epoch\": epoch,\n",
    "                \"Train Loss\": train_loss,\n",
    "                \"Train Acc\": train_acc,\n",
    "                \"Val Loss\": val_loss,\n",
    "                \"Val Acc\": val_acc,\n",
    "            })\n",
    "            print('Epoch: {} Train Loss: {:.4f} Train Acc: {:.4f} Val Loss: {:.4f} Val Acc: {:.4f}'.format(epoch, train_loss, train_acc, val_loss, val_acc))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Crudo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor modelo guardado con accuracy: 0.4393939393939394\n",
      "Epoch: 0 Train Loss: 0.9693 Train Acc: 0.0521 Val Loss: 0.9562 Val Acc: 0.4394\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[86], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_model(train_loader, val_loader, \u001b[38;5;241m10\u001b[39m)\n",
      "Cell \u001b[1;32mIn[85], line 17\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(train_loader, val_loader, n_epochs, best_val_acc)\u001b[0m\n\u001b[0;32m     14\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m \n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Entrenamiento\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28minput\u001b[39m,labels \u001b[38;5;129;01min\u001b[39;00m train_loader: \u001b[38;5;66;03m# Se recorren los datos de entrenamiento\u001b[39;00m\n\u001b[0;32m     18\u001b[0m     inputs, labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     19\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad() \u001b[38;5;66;03m# Se reinician los gradientes\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\richa\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\richa\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\richa\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:50\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[1;32m---> 50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\richa\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataset.py:420\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[1;34m(self, indices)\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx]] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "File \u001b[1;32mc:\\Users\\richa\\anaconda3\\Lib\\site-packages\\torchvision\\datasets\\folder.py:245\u001b[0m, in \u001b[0;36mDatasetFolder.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;124;03m    index (int): Index\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;124;03m    tuple: (sample, target) where target is class_index of the target class.\u001b[39;00m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    244\u001b[0m path, target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamples[index]\n\u001b[1;32m--> 245\u001b[0m sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader(path)\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    247\u001b[0m     sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(sample)\n",
      "File \u001b[1;32mc:\\Users\\richa\\anaconda3\\Lib\\site-packages\\torchvision\\datasets\\folder.py:284\u001b[0m, in \u001b[0;36mdefault_loader\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m accimage_loader(path)\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pil_loader(path)\n",
      "File \u001b[1;32mc:\\Users\\richa\\anaconda3\\Lib\\site-packages\\torchvision\\datasets\\folder.py:264\u001b[0m, in \u001b[0;36mpil_loader\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    263\u001b[0m     img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(f)\n\u001b[1;32m--> 264\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\richa\\anaconda3\\Lib\\site-packages\\PIL\\Image.py:941\u001b[0m, in \u001b[0;36mImage.convert\u001b[1;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[0;32m    889\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert\u001b[39m(\n\u001b[0;32m    890\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    891\u001b[0m     mode: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    895\u001b[0m     colors: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m256\u001b[39m,\n\u001b[0;32m    896\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Image:\n\u001b[0;32m    897\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    898\u001b[0m \u001b[38;5;124;03m    Returns a converted copy of this image. For the \"P\" mode, this\u001b[39;00m\n\u001b[0;32m    899\u001b[0m \u001b[38;5;124;03m    method translates pixels through the palette.  If mode is\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    938\u001b[0m \u001b[38;5;124;03m    :returns: An :py:class:`~PIL.Image.Image` object.\u001b[39;00m\n\u001b[0;32m    939\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 941\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload()\n\u001b[0;32m    943\u001b[0m     has_transparency \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransparency\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\n\u001b[0;32m    944\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    945\u001b[0m         \u001b[38;5;66;03m# determine default mode\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\richa\\anaconda3\\Lib\\site-packages\\PIL\\ImageFile.py:291\u001b[0m, in \u001b[0;36mImageFile.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    288\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n\u001b[0;32m    290\u001b[0m b \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m+\u001b[39m s\n\u001b[1;32m--> 291\u001b[0m n, err_code \u001b[38;5;241m=\u001b[39m decoder\u001b[38;5;241m.\u001b[39mdecode(b)\n\u001b[0;32m    292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_model(train_loader, val_loader, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d6b42e6544246029616e8e35e498b27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.322 MB of 0.735 MB uploaded\\r'), FloatProgress(value=0.4377599580563151, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>Train Acc</td><td>▅▆▆▅▇▃█▆▅▁</td></tr><tr><td>Train Loss</td><td>▄▅▆▇█▁█▄▅▃</td></tr><tr><td>Val Acc</td><td>▁█▇▅▇▆██▆▇</td></tr><tr><td>Val Loss</td><td>█▄▄▆▃▃▁▂▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>9</td></tr><tr><td>Train Acc</td><td>0.06161</td></tr><tr><td>Train Loss</td><td>0.32744</td></tr><tr><td>Val Acc</td><td>0.91892</td></tr><tr><td>Val Loss</td><td>0.26672</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">twilight-butterfly-29</strong> at: <a href='https://wandb.ai/iaredescnncnn-instituto-tecnol-gico-de-costa-rica/Model-A/runs/xybp24me' target=\"_blank\">https://wandb.ai/iaredescnncnn-instituto-tecnol-gico-de-costa-rica/Model-A/runs/xybp24me</a><br/> View project at: <a href='https://wandb.ai/iaredescnncnn-instituto-tecnol-gico-de-costa-rica/Model-A' target=\"_blank\">https://wandb.ai/iaredescnncnn-instituto-tecnol-gico-de-costa-rica/Model-A</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241014_214908-xybp24me\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset con filtro Bilateral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor modelo guardado con accuracy: 0.5675675675675675\n",
      "Epoch: 0 Train Loss: 0.3715 Train Acc: 0.0664 Val Loss: 1.0716 Val Acc: 0.5676\n",
      "Mejor modelo guardado con accuracy: 0.8108108108108109\n",
      "Epoch: 1 Train Loss: 0.2934 Train Acc: 0.0806 Val Loss: 0.5261 Val Acc: 0.8108\n",
      "Mejor modelo guardado con accuracy: 0.8378378378378379\n",
      "Epoch: 2 Train Loss: 0.2737 Train Acc: 0.0853 Val Loss: 0.3767 Val Acc: 0.8378\n",
      "Epoch: 3 Train Loss: 0.2426 Train Acc: 0.0758 Val Loss: 0.4045 Val Acc: 0.7838\n",
      "Epoch: 4 Train Loss: 0.2414 Train Acc: 0.0758 Val Loss: 0.3539 Val Acc: 0.8378\n",
      "Epoch: 5 Train Loss: 0.2286 Train Acc: 0.0853 Val Loss: 0.3914 Val Acc: 0.8108\n",
      "Mejor modelo guardado con accuracy: 0.8918918918918919\n",
      "Epoch: 6 Train Loss: 0.2456 Train Acc: 0.0806 Val Loss: 0.2612 Val Acc: 0.8919\n",
      "Epoch: 7 Train Loss: 0.2594 Train Acc: 0.0853 Val Loss: 0.2987 Val Acc: 0.8649\n",
      "Mejor modelo guardado con accuracy: 0.945945945945946\n",
      "Epoch: 8 Train Loss: 0.2589 Train Acc: 0.0806 Val Loss: 0.2439 Val Acc: 0.9459\n",
      "Epoch: 9 Train Loss: 0.2465 Train Acc: 0.0758 Val Loss: 0.2742 Val Acc: 0.8919\n"
     ]
    }
   ],
   "source": [
    "train_model(train_loader_bilateral, val_loader_bilateral, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cbaa8a51b40402a9f75aab7ee62c8da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.150 MB of 0.977 MB uploaded\\r'), FloatProgress(value=0.15347561684010336, max=1.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>Train Acc</td><td>▁▇▅▄▇▇█▄█▇</td></tr><tr><td>Train Loss</td><td>▆█▄▄▁▅▅▂▁▄</td></tr><tr><td>Val Acc</td><td>▁▅▇▆▄▇█▅█▇</td></tr><tr><td>Val Loss</td><td>█▇▄▆▆▃▁▄▁▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>9</td></tr><tr><td>Train Acc</td><td>0.08531</td></tr><tr><td>Train Loss</td><td>0.30809</td></tr><tr><td>Val Acc</td><td>0.91892</td></tr><tr><td>Val Loss</td><td>0.28679</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">kind-smoke-22</strong> at: <a href='https://wandb.ai/iaredescnncnn-instituto-tecnol-gico-de-costa-rica/Model-A/runs/h50wssbu' target=\"_blank\">https://wandb.ai/iaredescnncnn-instituto-tecnol-gico-de-costa-rica/Model-A/runs/h50wssbu</a><br/> View project at: <a href='https://wandb.ai/iaredescnncnn-instituto-tecnol-gico-de-costa-rica/Model-A' target=\"_blank\">https://wandb.ai/iaredescnncnn-instituto-tecnol-gico-de-costa-rica/Model-A</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241014_191912-h50wssbu\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset con filtro Canny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor modelo guardado con accuracy: 0.5135135135135136\n",
      "Epoch: 0 Train Loss: 0.9721 Train Acc: 0.0664 Val Loss: 1.0962 Val Acc: 0.5135\n",
      "Mejor modelo guardado con accuracy: 0.5945945945945946\n",
      "Epoch: 1 Train Loss: 0.8117 Train Acc: 0.0569 Val Loss: 0.8158 Val Acc: 0.5946\n",
      "Mejor modelo guardado con accuracy: 0.7027027027027027\n",
      "Epoch: 2 Train Loss: 0.7568 Train Acc: 0.0521 Val Loss: 0.7588 Val Acc: 0.7027\n",
      "Epoch: 3 Train Loss: 0.6020 Train Acc: 0.0711 Val Loss: 0.8532 Val Acc: 0.5676\n",
      "Epoch: 4 Train Loss: 0.6283 Train Acc: 0.0711 Val Loss: 0.8589 Val Acc: 0.6486\n",
      "Epoch: 5 Train Loss: 0.5582 Train Acc: 0.0664 Val Loss: 0.8215 Val Acc: 0.5946\n",
      "Epoch: 6 Train Loss: 0.5792 Train Acc: 0.0616 Val Loss: 0.8919 Val Acc: 0.6757\n",
      "Epoch: 7 Train Loss: 0.5916 Train Acc: 0.0711 Val Loss: 0.9229 Val Acc: 0.5946\n",
      "Epoch: 8 Train Loss: 0.6061 Train Acc: 0.0521 Val Loss: 0.7909 Val Acc: 0.6216\n",
      "Epoch: 9 Train Loss: 0.5334 Train Acc: 0.0521 Val Loss: 0.8524 Val Acc: 0.6757\n"
     ]
    }
   ],
   "source": [
    "train_model(train_loader_canny, val_loader_canny, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\richa\\AppData\\Local\\Temp\\ipykernel_5956\\2103782149.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  resnet50.load_state_dict(torch.load('best_model.pth'))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Se carga el modelo\n",
    "resnet50.load_state_dict(torch.load('best_model.pth'))\n",
    "\n",
    "def test_model(test_loader):\n",
    "    resnet50.eval()\n",
    "    test_corrects = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs,labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = resnet50(inputs)\n",
    "            _,predicted = torch.max(outputs, 1)\n",
    "            test_corrects += torch.sum(predicted == labels.data)\n",
    "\n",
    "        test_acc = test_corrects.double() / len(test_loader.dataset)\n",
    "    \n",
    "        print('Test Accuracy: {:.4f}'.format(test_acc))   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Crudo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.3939\n"
     ]
    }
   ],
   "source": [
    "test_model(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bilateral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.3939\n"
     ]
    }
   ],
   "source": [
    "test_model(test_loader_bilateral)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
