{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnG8uRdCh8Na"
      },
      "source": [
        "# Modelo B para clasificación de imágenes\n",
        "\n",
        "#### **Jeffrey Daniel Leiva Cascante** 2021016720\n",
        "#### **Richard Osvaldo León Chinchilla** 2019003759\n",
        "\n",
        "En este notebook se plantea el **modelo B** para la clasificación de imágenes de Covid-19, se realizan primero 3 **Proof of Concept** con diferentes arquitecturas, se aplican técnicas cómo el **Dropout** e **Inception Modules** para mejorar la capacidad de clasificación de los modelos.\n",
        "\n",
        "Se realizan las pruebas y se escoge el modelo con los mejores resultados para el subconjunto de pruebas; luego se procede a entrenar el modelo seleccionado con tres conjuntos de datos: el primero son los datos **crudos**, el segundo es de los datos con **bilateral filter** aplicado y el tercero es de los datos con el **canny edge filter** aplicado.\n",
        "\n",
        "Los datos se cargan utilizando la herramienta de **DataLoader** provista por PyTorch. Además, se utilizan técnicas de **Data Augmentation** que permitan tener un mayor número de ejemplos de imágenes para el entrenamiento del modelo; por medio de la utilización del módulo de **transforms** que PyTorch provee."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zcmg7q7Fh8Nv"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, SubsetRandomSampler, random_split\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "from torchsummary import summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNuSZWCkD8cL",
        "outputId": "1662b7ff-e877-48a8-ca14-45495fb706a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "8JRF-D3QxZlx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Definir funciones de training  y testing para las PoC.\n",
        "\n",
        "En este caso no contempla la funcionalidad de weights and biases, posteriormente se declara la función pero con la funcionalidad de weights and biases. Se entrena y se valida el modelo, se guardan los parámetros del modelo sí el validation accuracy mejora en cierto epoch.\n",
        "\n"
      ],
      "metadata": {
        "id": "tHQZoJ5kXYCl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model_with_subset(model, train_loader, test_loader, criterion, optimizer,save_model, epochs=10):\n",
        "    best_val_accuracy = -1\n",
        "    for epoch in range(epochs):\n",
        "        model.train()  # Poner el modelo en modo de entrenamiento\n",
        "\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        # Training\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()  # Limpiar los gradientes\n",
        "            outputs = model(inputs)  # Hacer una predicción\n",
        "            loss = criterion(outputs, labels)  # Calcular la pérdida\n",
        "            loss.backward()  # Hacer backpropagation\n",
        "            optimizer.step()  # Actualizar los pesos\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "        train_loss = running_loss / len(train_loader)\n",
        "        train_accuracy = 100 * correct / total\n",
        "\n",
        "        # Validation\n",
        "        model.eval()  # Setear el modelo a evalución\n",
        "        val_running_loss = 0.0\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "        with torch.no_grad():  # Desabilitar gradientes para validación.\n",
        "            for inputs, labels in test_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_running_loss += loss.item()\n",
        "\n",
        "                _, predicted = outputs.max(1)\n",
        "                val_total += labels.size(0)\n",
        "                val_correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "        val_loss = val_running_loss / len(test_loader)\n",
        "        val_accuracy = 100 * val_correct / val_total\n",
        "        if val_accuracy > best_val_accuracy:\n",
        "          best_val_accuracy = val_accuracy\n",
        "          torch.save(model.state_dict(), save_model)\n",
        "\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, \"\n",
        "              f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, \"\n",
        "              f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%\")\n",
        "\n",
        "def testing_model_with_subset(model, saved_model):\n",
        "  #Cargar los mejores parámetros de validación.\n",
        "  model.load_state_dict(torch.load(saved_model))\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  model.eval()\n",
        "  # debido a que no estamos entrenando, no necesitamos calcular los gradientes para las salidas\n",
        "  with torch.no_grad():\n",
        "      for images,labels in test_loader:\n",
        "          images, labels = images.to(device), labels.to(device)\n",
        "          # calcular outputs corriendo imagenes en la red\n",
        "          outputs = model(images)\n",
        "          # La clase con mayor valor es la que escogemos como salida\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == labels).sum().item()\n",
        "\n",
        "  print(f'Accuracy de la red en las imagenes de test: {100 * correct / total:.2f} %')"
      ],
      "metadata": {
        "id": "L4VKwucLYEVf"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Carga de datos y utilización de transformers para las Proof of Concept.\n",
        "\n",
        "Se carga un **20%** de los datos para realizar las tres **proof of concept** con los diferentes modelos que se van a plantear, se utiliza una semilla para asegurar la repetibilidad de los experimentos.\n",
        "\n",
        "Se utiliza el módulo de **transforms** para aplicar transformaciones a las imágenes de entrada, en el caso de los datos de entrenamiento para las PoC se aplican técnicas de **Data Augmentation** cómo normalización, en este caso para no introducir más aleatoridad a las pruebas no se tienen inversiones o rotaciones, para el entrenamiento del modelo escogido a partir de las pruebas si se utilizarán estas técnicas.\n",
        "\n",
        "Al utilizar un conjunto reducido de datos para las PoC se utiliza el DataLoader con un tamaño de **batch de 8** para ambos datasets."
      ],
      "metadata": {
        "id": "sRZWeO_PPIFr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_transforms = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),  # Redimensionar a 128x128\n",
        "    transforms.Grayscale(num_output_channels=1),  # Convertir a escala de grises\n",
        "    transforms.ToTensor(),  # Convertir a tensor\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])  # Normalización\n",
        "])\n",
        "\n",
        "\n",
        "test_data_transforms = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),  # Redimensionar a 128x128\n",
        "    transforms.Grayscale(num_output_channels=1),  # Convertir a escala de grises\n",
        "    transforms.ToTensor(),   # Convertir a tensor\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])  # Normalización\n",
        "])\n",
        "\n",
        "\n",
        "# Definir las rutas a las carpetas\n",
        "train_dir = './drive/MyDrive/Covid19-dataset/train'\n",
        "test_dir = './drive/MyDrive/Covid19-dataset/test'\n",
        "\n",
        "train_dataset = datasets.ImageFolder(root=train_dir, transform=train_data_transforms)\n",
        "test_dataset = datasets.ImageFolder(root=test_dir, transform=test_data_transforms)\n",
        "\n",
        "# Definir el tamaño del subconjunto que quieres usar\n",
        "subset_size = 0.2  # Por ejemplo, usar el 20% de los datos\n",
        "\n",
        "# Obtener los índices aleatorios para el subconjunto del conjunto de entrenamiento\n",
        "np.random.seed(42)\n",
        "train_size = len(train_dataset)\n",
        "indices = list(range(train_size))\n",
        "np.random.shuffle(indices)  # Mezclar los índices\n",
        "\n",
        "subset_indices = indices[:int(subset_size * train_size)]  # Obtener el subconjunto\n",
        "\n",
        "# Crear un SubsetRandomSampler con los índices seleccionados\n",
        "train_sampler = SubsetRandomSampler(subset_indices)\n",
        "\n",
        "# Obtener los índices aleatorios para el subconjunto del conjunto de testing\n",
        "test_size = len(test_dataset)\n",
        "indices_test = list(range(test_size))\n",
        "np.random.shuffle(indices_test)  # Mezclar los índices\n",
        "\n",
        "subset_indices_test = indices_test[:int(subset_size * test_size)]  # Obtener el subconjunto\n",
        "\n",
        "# Crear un SubsetRandomSampler con los índices seleccionados\n",
        "test_sampler = SubsetRandomSampler(subset_indices_test)\n",
        "\n",
        "# Definir DataLoader para el conjunto de entrenamiento con el subconjunto de datos\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, sampler=train_sampler)\n",
        "\n",
        "# También puedes crear un DataLoader para el conjunto de prueba completo\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, sampler=test_sampler)"
      ],
      "metadata": {
        "id": "EUMldrBMPDmV"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El siguiente código muestra el mapeo de clases a índices que realizar pytorch; algunas de las imágenes presentes en el data loader de testing, además de la **etiqueta** que corresponde a cada una de ellas, para tener una idea de los datos."
      ],
      "metadata": {
        "id": "Fo11k-ACXQth"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classes = ('Covid', 'Normal','Viral Pneumonia')\n",
        "\n",
        "print(f\"Cantidad de test samples: {len(test_loader.dataset)}\")\n",
        "\n",
        "#Para ver com se asignan las etiquetas a cada clase en el set de training\n",
        "print(train_dataset.class_to_idx)\n",
        "#Lo mismo pero para el set de testing\n",
        "print(test_dataset.class_to_idx)\n",
        "\n",
        "dataiter = iter(test_loader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "print(labels)\n",
        "\n",
        "def imshow(img):\n",
        "    # Desnormalizar: (img * std) + mean\n",
        "    img = img * 0.5 + 0.5  # Desnormalizar usando mean=0.5 y std=0.5\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)), cmap='gray')  # Añadir cmap si es necesario\n",
        "    plt.show()\n",
        "\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "\n",
        "print('GroundTruth')\n",
        "for j in range(8):\n",
        "    print(f'{classes[labels[j]]:5s}')"
      ],
      "metadata": {
        "id": "9-zD8EsgiFT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4s3Y5hHrvgzp"
      },
      "source": [
        "## Propuesta de modelo 1\n",
        "\n",
        "Para la propuesta #1 del modelo B tenemos la siguiente arquitectura:\n",
        "\n",
        "- La primera capa es una capa de convolución de dos dimensiones que recibe la imágen de 1 canal (en escala de grises), aplica 64 filtros con tamaño de kernel 3 y padding de 1, lo que da como resultado la salida de 128x128x64.\n",
        "\n",
        "- La segunda capa aplica max pooling con un kernel de 2 y stride de 2, lo que produce una salida de 64x64x64.\n",
        "\n",
        "- Seguido de esto se tiene el módulo de Inception, que aplica varias operaciones de convolución y pooling en paralelo, lo que permite que el modelo aprenda mejor las características a diferentes niveles de complejidad. Cuenta con 4 ramas, en las que se aplican diversos tamaños de kernels y la salida de las ramas es de 64x64x128. Todas estas se concatenan y su salida es de 64x64x512.\n",
        "\n",
        "- Después se vuelve a aplicar max pooling con kernel de 2 y stride de 2, lo que da cómo resultado una salida de 32x32x512, se hace el flatten de la misma y esta es la entrada de la primera capa fully connected.\n",
        "\n",
        "- La capa primer capa fully connected  produce 128 canales de salida. La última capa tiene 128 canales de entrada y 3 de salida correspondientes a las tres categorías de imagenes.\n",
        "\n",
        "**Se utiliza reLU cómo función de activación para las capas convolucionales y la primera capa fully connected**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "jTjOohHDvb_Z"
      },
      "outputs": [],
      "source": [
        "class InceptionModuleOne(nn.Module):\n",
        "  def __init__(self, chanels):\n",
        "    super(InceptionModuleOne, self).__init__()\n",
        "\n",
        "    self.branch1 = nn.Conv2d(chanels, 128, kernel_size=1)\n",
        "\n",
        "    self.branch2 = nn.Sequential(\n",
        "        nn.Conv2d(chanels, 128, kernel_size=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "    self.branch3 = nn.Sequential(\n",
        "        nn.Conv2d(chanels, 128, kernel_size=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(128, 128, kernel_size=5, padding=2),\n",
        "        nn.ReLU(),\n",
        "    )\n",
        "\n",
        "    self.branch4 = nn.Sequential(\n",
        "        nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
        "        nn.Conv2d(chanels, 128, kernel_size=1),\n",
        "        nn.ReLU(),\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    branch1 = F.relu(self.branch1(x))\n",
        "    branch2 = self.branch2(x)\n",
        "    branch3 = self.branch3(x)\n",
        "    branch4 = self.branch4(x)\n",
        "    return torch.cat([branch1, branch2, branch3, branch4],1)\n",
        "\n",
        "\n",
        "class CNNModelBOne(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNNModelBOne, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 64, kernel_size=3, padding=1)\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.inception = InceptionModuleOne(64)\n",
        "    self.dropout = nn.Dropout(0.2)\n",
        "    self.fc1 = nn.Linear(512 *32 *32, 128)\n",
        "    self.fc2 = nn.Linear(128 , 3)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = F.relu(self.conv1(x))\n",
        "    x = self.pool(x)\n",
        "    x = self.inception(x)\n",
        "    x = self.pool(x)\n",
        "    x = self.dropout(x)\n",
        "    x = torch.flatten(x,1)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = self.fc2(x)\n",
        "    return x\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12nJbPdVFopw"
      },
      "source": [
        "### Proof of Concept Modelo 1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se procede a realizar la prueba de concepto con el primer modelo planteado. Se visualiza el accuracy del conjunto de entrenamiento y validación por cada epoch. En este caso se realizan **50 epochs**. Se va a guardar el modelo cuando presente un mejor accuracy al al anterior.\n",
        "\n",
        "Para el optimizador se utiliza el Stochastic Gradient Descent que nos facilita el módulo **optim**, además cómo función de pérdida se utiliza **Cross Entropy Loss**.\n",
        "\n",
        "Además se define una función para el entrenamiento con los subsets"
      ],
      "metadata": {
        "id": "lXETmFr1ndhr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdbfJ79pFqrz",
        "outputId": "5087dd57-4abb-44ff-c251-f401686c8679"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50, Train Loss: 1.0660, Train Accuracy: 42.00%, Val Loss: 1.0834, Val Accuracy: 38.46%\n",
            "Epoch 2/50, Train Loss: 0.7942, Train Accuracy: 62.00%, Val Loss: 1.1324, Val Accuracy: 38.46%\n",
            "Epoch 3/50, Train Loss: 0.5552, Train Accuracy: 84.00%, Val Loss: 0.8823, Val Accuracy: 46.15%\n",
            "Epoch 4/50, Train Loss: 0.3244, Train Accuracy: 88.00%, Val Loss: 0.6818, Val Accuracy: 69.23%\n",
            "Epoch 5/50, Train Loss: 0.3285, Train Accuracy: 90.00%, Val Loss: 1.2003, Val Accuracy: 46.15%\n",
            "Epoch 6/50, Train Loss: 0.2778, Train Accuracy: 90.00%, Val Loss: 0.7242, Val Accuracy: 61.54%\n",
            "Epoch 7/50, Train Loss: 0.1747, Train Accuracy: 94.00%, Val Loss: 0.7371, Val Accuracy: 69.23%\n",
            "Epoch 8/50, Train Loss: 0.1454, Train Accuracy: 94.00%, Val Loss: 0.8218, Val Accuracy: 53.85%\n",
            "Epoch 9/50, Train Loss: 0.1108, Train Accuracy: 92.00%, Val Loss: 0.8689, Val Accuracy: 53.85%\n",
            "Epoch 10/50, Train Loss: 0.0997, Train Accuracy: 94.00%, Val Loss: 0.8723, Val Accuracy: 61.54%\n",
            "Epoch 11/50, Train Loss: 0.0894, Train Accuracy: 96.00%, Val Loss: 0.8863, Val Accuracy: 53.85%\n",
            "Epoch 12/50, Train Loss: 0.0785, Train Accuracy: 96.00%, Val Loss: 0.8199, Val Accuracy: 53.85%\n",
            "Epoch 13/50, Train Loss: 0.0622, Train Accuracy: 98.00%, Val Loss: 0.9830, Val Accuracy: 53.85%\n",
            "Epoch 14/50, Train Loss: 0.0582, Train Accuracy: 98.00%, Val Loss: 0.6914, Val Accuracy: 53.85%\n",
            "Epoch 15/50, Train Loss: 0.0510, Train Accuracy: 100.00%, Val Loss: 0.6701, Val Accuracy: 69.23%\n",
            "Epoch 16/50, Train Loss: 0.0444, Train Accuracy: 100.00%, Val Loss: 0.6940, Val Accuracy: 76.92%\n",
            "Epoch 17/50, Train Loss: 0.0412, Train Accuracy: 100.00%, Val Loss: 0.8559, Val Accuracy: 61.54%\n",
            "Epoch 18/50, Train Loss: 0.0473, Train Accuracy: 100.00%, Val Loss: 0.7744, Val Accuracy: 53.85%\n",
            "Epoch 19/50, Train Loss: 0.0410, Train Accuracy: 100.00%, Val Loss: 0.6602, Val Accuracy: 76.92%\n",
            "Epoch 20/50, Train Loss: 0.0362, Train Accuracy: 100.00%, Val Loss: 0.8261, Val Accuracy: 76.92%\n",
            "Epoch 21/50, Train Loss: 0.0263, Train Accuracy: 100.00%, Val Loss: 0.8708, Val Accuracy: 61.54%\n",
            "Epoch 22/50, Train Loss: 0.0253, Train Accuracy: 100.00%, Val Loss: 0.9409, Val Accuracy: 69.23%\n",
            "Epoch 23/50, Train Loss: 0.0237, Train Accuracy: 100.00%, Val Loss: 0.7830, Val Accuracy: 69.23%\n",
            "Epoch 24/50, Train Loss: 0.0214, Train Accuracy: 100.00%, Val Loss: 0.9505, Val Accuracy: 76.92%\n",
            "Epoch 25/50, Train Loss: 0.0228, Train Accuracy: 100.00%, Val Loss: 1.0111, Val Accuracy: 76.92%\n",
            "Epoch 26/50, Train Loss: 0.0166, Train Accuracy: 100.00%, Val Loss: 1.2023, Val Accuracy: 53.85%\n",
            "Epoch 27/50, Train Loss: 0.0193, Train Accuracy: 100.00%, Val Loss: 0.8547, Val Accuracy: 69.23%\n",
            "Epoch 28/50, Train Loss: 0.0228, Train Accuracy: 100.00%, Val Loss: 0.7744, Val Accuracy: 76.92%\n",
            "Epoch 29/50, Train Loss: 0.0171, Train Accuracy: 100.00%, Val Loss: 0.7015, Val Accuracy: 84.62%\n",
            "Epoch 30/50, Train Loss: 0.0230, Train Accuracy: 100.00%, Val Loss: 1.0198, Val Accuracy: 69.23%\n",
            "Epoch 31/50, Train Loss: 0.0146, Train Accuracy: 100.00%, Val Loss: 0.6828, Val Accuracy: 84.62%\n",
            "Epoch 32/50, Train Loss: 0.0134, Train Accuracy: 100.00%, Val Loss: 0.8389, Val Accuracy: 76.92%\n",
            "Epoch 33/50, Train Loss: 0.0126, Train Accuracy: 100.00%, Val Loss: 1.1809, Val Accuracy: 69.23%\n",
            "Epoch 34/50, Train Loss: 0.0115, Train Accuracy: 100.00%, Val Loss: 0.8603, Val Accuracy: 61.54%\n",
            "Epoch 35/50, Train Loss: 0.0096, Train Accuracy: 100.00%, Val Loss: 0.8745, Val Accuracy: 76.92%\n",
            "Epoch 36/50, Train Loss: 0.0096, Train Accuracy: 100.00%, Val Loss: 0.7710, Val Accuracy: 76.92%\n",
            "Epoch 37/50, Train Loss: 0.0116, Train Accuracy: 100.00%, Val Loss: 0.9285, Val Accuracy: 69.23%\n",
            "Epoch 38/50, Train Loss: 0.0081, Train Accuracy: 100.00%, Val Loss: 0.8351, Val Accuracy: 69.23%\n",
            "Epoch 39/50, Train Loss: 0.0077, Train Accuracy: 100.00%, Val Loss: 0.9776, Val Accuracy: 69.23%\n",
            "Epoch 40/50, Train Loss: 0.0095, Train Accuracy: 100.00%, Val Loss: 1.1290, Val Accuracy: 76.92%\n",
            "Epoch 41/50, Train Loss: 0.0075, Train Accuracy: 100.00%, Val Loss: 1.0708, Val Accuracy: 61.54%\n",
            "Epoch 42/50, Train Loss: 0.0072, Train Accuracy: 100.00%, Val Loss: 1.3250, Val Accuracy: 61.54%\n",
            "Epoch 43/50, Train Loss: 0.0071, Train Accuracy: 100.00%, Val Loss: 1.0944, Val Accuracy: 76.92%\n",
            "Epoch 44/50, Train Loss: 0.0086, Train Accuracy: 100.00%, Val Loss: 0.8161, Val Accuracy: 76.92%\n",
            "Epoch 45/50, Train Loss: 0.0063, Train Accuracy: 100.00%, Val Loss: 1.0630, Val Accuracy: 76.92%\n",
            "Epoch 46/50, Train Loss: 0.0064, Train Accuracy: 100.00%, Val Loss: 0.9786, Val Accuracy: 76.92%\n",
            "Epoch 47/50, Train Loss: 0.0055, Train Accuracy: 100.00%, Val Loss: 0.9186, Val Accuracy: 76.92%\n",
            "Epoch 48/50, Train Loss: 0.0054, Train Accuracy: 100.00%, Val Loss: 0.9926, Val Accuracy: 69.23%\n",
            "Epoch 49/50, Train Loss: 0.0060, Train Accuracy: 100.00%, Val Loss: 1.0268, Val Accuracy: 61.54%\n",
            "Epoch 50/50, Train Loss: 0.0051, Train Accuracy: 100.00%, Val Loss: 0.9960, Val Accuracy: 76.92%\n"
          ]
        }
      ],
      "source": [
        "model = CNNModelBOne()\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Entrenar el modelo con validación.\n",
        "train_model_with_subset(model, train_loader, test_loader, criterion, optimizer, epochs=50, save_model=\"best_parameters_poc_one.pth\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Resultados de la prueba con la propuesta de modelo 1\n",
        "\n",
        "En este caso, los resultados con el modelo 1 nos dan un 84% de accuracy con los datos de prueba, lo cual es un buen porcentaje para la pequeña cantidad de datos de entrenamiento que se le han dado."
      ],
      "metadata": {
        "id": "kcONzEZ_U6NQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFhx9k6n5Erh",
        "outputId": "3fe07164-171e-4c37-8776-e3c33e5a771b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-34-bc51a58bf24f>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('best_parameters_poc_one.pth'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy de la red en las imagenes de test: 84.62 %\n"
          ]
        }
      ],
      "source": [
        "testing_model_with_subset(model, 'best_parameters_poc_one.pth' )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2rOd8cn7XdD"
      },
      "source": [
        "## Propuesta de modelo 2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta es la segunda propuesta de modelo B. Esta arquitectura de modelo es más compleja que la anterior, se aplican otras técnicas de normalización que ayuden al modelo a generalizar mejor los datos, en este se incluye un único módulo de Inception, además de varias capas de convolución, max pooling y dropout. Además se utiliza Batch Normalization, la cual es una técnica para normalizar las activaciones en capas intermedias de redes neuronales profundas, además ha demostrado mejorar el accuracy y acelerar el proceso de entrenamiento. (Bjork et al, 2018).\n",
        "\n",
        "\n",
        "- En primer lugar se tiene una capa de convolución en el que se aplican 32 filtros, con un kernel de 3x3 y padding de 1, su salida es de 128x128x32.\n",
        "\n",
        "- La segunda capa de convolución aplica 64 filtros con un kernel de 3 y padding de 1, su salida es de 128x128x64.\n",
        "\n",
        "- Seguido se aplica max pooling con kernel de 2 y stride de 2, la salida es de 64x64x64.\n",
        "\n",
        "- Luego se aplica el 1er dropout con una probabilidad de 0.2.\n",
        "\n",
        "- Seguido de esto se tiene el módulo de Inception, que aplica varias operaciones de convolución y pooling en paralelo. Cuenta con 4 ramas, la primera produce 32 feature maps, la segunda 64, la tercera 64 y la cuarta 32, se concatenan y dan como salida 64x64x192.\n",
        "\n",
        "- La tercera convolución produce una salida de 64x64x128.\n",
        "\n",
        "- Luego se aplica de nuevo max pooling lo que reduce las dimensiones a 32x32x128.\n",
        "\n",
        "- Seguido, se aplica la cuarta convolución, que produce como salida 32x32x256.\n",
        "\n",
        "-Se aplica después el segundo dropout con una probabilidad de 0.25.\n",
        "\n",
        "- Se hace el flatten, la primera fully connected produce 512 salidas, la segunda, la segunda produce 128 y la tercera produce 3 salidas correspondientes con las categorías de imágenes.\n",
        "\n",
        "\n",
        "**Se aplica la función de activación reLU en las capas convolucionales y fully connected.**\n",
        "\n",
        "**Después de cada convolución se aplica la función BatchNorm2d.**"
      ],
      "metadata": {
        "id": "-nXqr5lpqtaY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class InceptionModuleTwo(nn.Module):\n",
        "  def __init__(self, chanels):\n",
        "    super(InceptionModuleTwo, self).__init__()\n",
        "\n",
        "    self.branch1 = nn.Sequential(\n",
        "        nn.Conv2d(chanels, 32, kernel_size=1),\n",
        "        nn.BatchNorm2d(32),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "    self.branch2 = nn.Sequential(\n",
        "        nn.Conv2d(chanels, 32, kernel_size=1),\n",
        "        nn.BatchNorm2d(32),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "    self.branch3 = nn.Sequential(\n",
        "        nn.Conv2d(chanels, 32, kernel_size=1),\n",
        "        nn.BatchNorm2d(32),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(32, 64, kernel_size=5, padding=2),\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.ReLU(),\n",
        "    )\n",
        "\n",
        "    self.branch4 = nn.Sequential(\n",
        "        nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
        "        nn.Conv2d(chanels, 32, kernel_size=1),\n",
        "        nn.BatchNorm2d(32),\n",
        "        nn.ReLU(),\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    branch1 = self.branch1(x)\n",
        "    branch2 = self.branch2(x)\n",
        "    branch3 = self.branch3(x)\n",
        "    branch4 = self.branch4(x)\n",
        "    return torch.cat([branch1, branch2, branch3, branch4],1)\n",
        "\n",
        "\n",
        "class CNNModelBTwo(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNModelBTwo, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.dropout1 = nn.Dropout(0.2)\n",
        "\n",
        "        self.inception = InceptionModuleTwo(64)\n",
        "\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(192, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.conv4 = nn.Sequential(\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.dropout2 = nn.Dropout(0.25)\n",
        "\n",
        "        self.fc1 = nn.Linear(32 * 32 * 256, 512)\n",
        "        self.dropout_fc = nn.Dropout(0.4)\n",
        "        self.fc2 = nn.Linear(512, 128)\n",
        "        self.fc3 = nn.Linear(128, 3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.pool(self.conv2(x))\n",
        "        x = self.dropout1(x)\n",
        "        x = self.inception(x)\n",
        "        x = self.pool(self.conv3(x))\n",
        "        x = self.conv4(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n"
      ],
      "metadata": {
        "id": "cEGxrHc3NU1J"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Proof of Concept modelo 2\n",
        "\n",
        "\n",
        "Se procede a realizar la prueba de concepto con el primer modelo planteado. Se visualiza el accuracy del conjunto de entrenamiento y validación por cada epoch. En este caso se realizan **50 epochs**.\n",
        "\n",
        "Para el optimizador se utiliza el **Adam** que nos facilita el módulo **optim** en este caso, este nos puede ayudar a converger más rápido , además cómo función de pérdida se utiliza **Cross Entropy Loss**."
      ],
      "metadata": {
        "id": "l_SCzPYouRoR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = CNNModelBTwo()\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "#Utilizamos la función previamente definida.\n",
        "train_model_with_subset(model, train_loader, test_loader, criterion, optimizer, epochs=50, save_model=\"best_parameters_poc_two.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ej-Q5nuRS6Qb",
        "outputId": "d6191ddd-3525-4067-8f2b-1575f9089c9d"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50, Train Loss: 12.7501, Train Accuracy: 62.00%, Val Loss: 63.8166, Val Accuracy: 23.08%\n",
            "Epoch 2/50, Train Loss: 6.0568, Train Accuracy: 74.00%, Val Loss: 112.3934, Val Accuracy: 23.08%\n",
            "Epoch 3/50, Train Loss: 5.5840, Train Accuracy: 68.00%, Val Loss: 65.0470, Val Accuracy: 23.08%\n",
            "Epoch 4/50, Train Loss: 0.8002, Train Accuracy: 88.00%, Val Loss: 35.4831, Val Accuracy: 23.08%\n",
            "Epoch 5/50, Train Loss: 1.6627, Train Accuracy: 82.00%, Val Loss: 21.8833, Val Accuracy: 30.77%\n",
            "Epoch 6/50, Train Loss: 0.5386, Train Accuracy: 88.00%, Val Loss: 12.0419, Val Accuracy: 53.85%\n",
            "Epoch 7/50, Train Loss: 0.4646, Train Accuracy: 94.00%, Val Loss: 1.3442, Val Accuracy: 84.62%\n",
            "Epoch 8/50, Train Loss: 0.0502, Train Accuracy: 98.00%, Val Loss: 0.9461, Val Accuracy: 84.62%\n",
            "Epoch 9/50, Train Loss: 0.3206, Train Accuracy: 94.00%, Val Loss: 0.0627, Val Accuracy: 100.00%\n",
            "Epoch 10/50, Train Loss: 0.0441, Train Accuracy: 98.00%, Val Loss: 0.1227, Val Accuracy: 92.31%\n",
            "Epoch 11/50, Train Loss: 0.0001, Train Accuracy: 100.00%, Val Loss: 1.4622, Val Accuracy: 84.62%\n",
            "Epoch 12/50, Train Loss: 0.0230, Train Accuracy: 98.00%, Val Loss: 1.8144, Val Accuracy: 84.62%\n",
            "Epoch 13/50, Train Loss: 0.1505, Train Accuracy: 96.00%, Val Loss: 0.9751, Val Accuracy: 84.62%\n",
            "Epoch 14/50, Train Loss: 0.0280, Train Accuracy: 98.00%, Val Loss: 0.6135, Val Accuracy: 84.62%\n",
            "Epoch 15/50, Train Loss: 0.0004, Train Accuracy: 100.00%, Val Loss: 2.2864, Val Accuracy: 76.92%\n",
            "Epoch 16/50, Train Loss: 0.0170, Train Accuracy: 100.00%, Val Loss: 0.5130, Val Accuracy: 92.31%\n",
            "Epoch 17/50, Train Loss: 0.0000, Train Accuracy: 100.00%, Val Loss: 0.0001, Val Accuracy: 100.00%\n",
            "Epoch 18/50, Train Loss: 0.0004, Train Accuracy: 100.00%, Val Loss: 0.0006, Val Accuracy: 100.00%\n",
            "Epoch 19/50, Train Loss: 0.0007, Train Accuracy: 100.00%, Val Loss: 0.0004, Val Accuracy: 100.00%\n",
            "Epoch 20/50, Train Loss: 0.0001, Train Accuracy: 100.00%, Val Loss: 0.0005, Val Accuracy: 100.00%\n",
            "Epoch 21/50, Train Loss: 0.0006, Train Accuracy: 100.00%, Val Loss: 0.0009, Val Accuracy: 100.00%\n",
            "Epoch 22/50, Train Loss: 0.0000, Train Accuracy: 100.00%, Val Loss: 0.0012, Val Accuracy: 100.00%\n",
            "Epoch 23/50, Train Loss: 0.0000, Train Accuracy: 100.00%, Val Loss: 0.0018, Val Accuracy: 100.00%\n",
            "Epoch 24/50, Train Loss: 0.0000, Train Accuracy: 100.00%, Val Loss: 0.0010, Val Accuracy: 100.00%\n",
            "Epoch 25/50, Train Loss: 0.0000, Train Accuracy: 100.00%, Val Loss: 0.0020, Val Accuracy: 100.00%\n",
            "Epoch 26/50, Train Loss: 0.0000, Train Accuracy: 100.00%, Val Loss: 0.0019, Val Accuracy: 100.00%\n",
            "Epoch 27/50, Train Loss: 0.0000, Train Accuracy: 100.00%, Val Loss: 0.0013, Val Accuracy: 100.00%\n",
            "Epoch 28/50, Train Loss: 0.0000, Train Accuracy: 100.00%, Val Loss: 0.0032, Val Accuracy: 100.00%\n",
            "Epoch 29/50, Train Loss: 0.0000, Train Accuracy: 100.00%, Val Loss: 0.0041, Val Accuracy: 100.00%\n",
            "Epoch 30/50, Train Loss: 0.0000, Train Accuracy: 100.00%, Val Loss: 0.2572, Val Accuracy: 92.31%\n",
            "Epoch 31/50, Train Loss: 0.0000, Train Accuracy: 100.00%, Val Loss: 0.5895, Val Accuracy: 92.31%\n",
            "Epoch 32/50, Train Loss: 0.0000, Train Accuracy: 100.00%, Val Loss: 0.7011, Val Accuracy: 84.62%\n",
            "Epoch 33/50, Train Loss: 0.0000, Train Accuracy: 100.00%, Val Loss: 1.0221, Val Accuracy: 84.62%\n",
            "Epoch 34/50, Train Loss: 0.0000, Train Accuracy: 100.00%, Val Loss: 0.0320, Val Accuracy: 100.00%\n",
            "Epoch 35/50, Train Loss: 0.0000, Train Accuracy: 100.00%, Val Loss: 0.0025, Val Accuracy: 100.00%\n",
            "Epoch 36/50, Train Loss: 0.0000, Train Accuracy: 100.00%, Val Loss: 0.0010, Val Accuracy: 100.00%\n",
            "Epoch 37/50, Train Loss: 0.0000, Train Accuracy: 100.00%, Val Loss: 0.0015, Val Accuracy: 100.00%\n",
            "Epoch 38/50, Train Loss: 0.7578, Train Accuracy: 98.00%, Val Loss: 8.7392, Val Accuracy: 61.54%\n",
            "Epoch 39/50, Train Loss: 1.8510, Train Accuracy: 88.00%, Val Loss: 0.3425, Val Accuracy: 92.31%\n",
            "Epoch 40/50, Train Loss: 0.8143, Train Accuracy: 94.00%, Val Loss: 18.5277, Val Accuracy: 53.85%\n",
            "Epoch 41/50, Train Loss: 1.0865, Train Accuracy: 96.00%, Val Loss: 3.4769, Val Accuracy: 69.23%\n",
            "Epoch 42/50, Train Loss: 0.2956, Train Accuracy: 98.00%, Val Loss: 0.2650, Val Accuracy: 92.31%\n",
            "Epoch 43/50, Train Loss: 0.1622, Train Accuracy: 98.00%, Val Loss: 2.1770, Val Accuracy: 84.62%\n",
            "Epoch 44/50, Train Loss: 0.5075, Train Accuracy: 88.00%, Val Loss: 8.8396, Val Accuracy: 53.85%\n",
            "Epoch 45/50, Train Loss: 0.9049, Train Accuracy: 94.00%, Val Loss: 0.0048, Val Accuracy: 100.00%\n",
            "Epoch 46/50, Train Loss: 0.0034, Train Accuracy: 100.00%, Val Loss: 0.0096, Val Accuracy: 100.00%\n",
            "Epoch 47/50, Train Loss: 0.0145, Train Accuracy: 100.00%, Val Loss: 2.6028, Val Accuracy: 76.92%\n",
            "Epoch 48/50, Train Loss: 0.4322, Train Accuracy: 96.00%, Val Loss: 0.2335, Val Accuracy: 92.31%\n",
            "Epoch 49/50, Train Loss: 0.6706, Train Accuracy: 94.00%, Val Loss: 31.1842, Val Accuracy: 53.85%\n",
            "Epoch 50/50, Train Loss: 0.9004, Train Accuracy: 94.00%, Val Loss: 9.1135, Val Accuracy: 69.23%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Resultados de la prueba con la propuesta de modelo 2\n",
        "\n",
        "En este caso el accuracy es del 84.62% para las imágenes de prueba al igual que la propuesta de modelo 1. Puede que el modelo en la práctica y con todos los datos tenga un mejor rendimiento al ser un poco más complejo y poder extraer mejor las características de los datos."
      ],
      "metadata": {
        "id": "SQDnOJLuUa2O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "testing_model_with_subset(model, 'best_parameters_poc_two.pth' )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPGUIYhkXn7H",
        "outputId": "22b5facb-782c-4a61-b208-33e91d7ff94f"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-38-18fb53be2098>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('best_parameters_poc_two.pth'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy de la red en las imagenes de test: 100.00 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Propuesta de modelo 3\n",
        "\n",
        "Para la tercera propuesta se tiene un modelo más complejo, en este caso se utilizan dos módulos de Inception con un número mayor de filtros, de igual manera se aplican técnicas como batch normalization y dropout.\n",
        "\n"
      ],
      "metadata": {
        "id": "uFTMOw6FNEbs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class InceptionModule(nn.Module):\n",
        "    def __init__(self, in_channels, out1x1, red3x3, out3x3, red5x5, out5x5, pool_proj):\n",
        "        super(InceptionModule, self).__init__()\n",
        "\n",
        "        # Branch 1: 1x1 Conv\n",
        "        self.branch1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out1x1, kernel_size=1),\n",
        "            nn.BatchNorm2d(out1x1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        # Branch 2: 1x1 Conv -> 3x3 Conv\n",
        "        self.branch2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, red3x3, kernel_size=1),\n",
        "            nn.BatchNorm2d(red3x3),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(red3x3, out3x3, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out3x3),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        # Branch 3: 1x1 Conv -> 5x5 Conv\n",
        "        self.branch3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, red5x5, kernel_size=1),\n",
        "            nn.BatchNorm2d(red5x5),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(red5x5, out5x5, kernel_size=5, padding=2),\n",
        "            nn.BatchNorm2d(out5x5),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        # Branch 4: Max Pool -> 1x1 Conv\n",
        "        self.branch4 = nn.Sequential(\n",
        "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
        "            nn.Conv2d(in_channels, pool_proj, kernel_size=1),\n",
        "            nn.BatchNorm2d(pool_proj),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        branch1 = self.branch1(x)\n",
        "        branch2 = self.branch2(x)\n",
        "        branch3 = self.branch3(x)\n",
        "        branch4 = self.branch4(x)\n",
        "        return torch.cat([branch1, branch2, branch3, branch4], 1)\n",
        "\n",
        "\n",
        "class CNNModelWithTwoInception(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNModelWithTwoInception, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        # Primer Inception module\n",
        "        self.inception1 = InceptionModule(64, 32, 32, 64, 16, 32, 32)\n",
        "\n",
        "        # Segundo Inception module\n",
        "        self.inception2 = InceptionModule(160, 64, 64, 128, 32, 64, 64)\n",
        "\n",
        "        # Pooling layer\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Dropout\n",
        "        self.dropout1 = nn.Dropout(0.3)\n",
        "        self.dropout2 = nn.Dropout(0.4)\n",
        "\n",
        "        # Global average pooling\n",
        "        self.global_avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "\n",
        "        # Fully connected\n",
        "        self.fc1 = nn.Linear(320, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Conv layers\n",
        "        x = self.conv1(x)\n",
        "        x = self.pool(self.conv2(x))\n",
        "\n",
        "        # Primer Inception module\n",
        "        x = self.inception1(x)\n",
        "\n",
        "        # Pool después de primer inception\n",
        "        x = self.pool(x)\n",
        "\n",
        "        # Segundo Inception Module\n",
        "        x = self.inception2(x)\n",
        "\n",
        "        # Pooling\n",
        "        x = self.pool(x)\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        # Global average pooling\n",
        "        x = self.global_avg_pool(x)\n",
        "\n",
        "        # Flatten\n",
        "        x = torch.flatten(x, 1)\n",
        "\n",
        "        # Fully connected con dropout\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout2(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "\n",
        "        # Salida\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "2WOxuegVIt8l"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = CNNModelWithTwoInception()\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "\n",
        "train_model_with_subset(model, train_loader, test_loader, criterion, optimizer, epochs=50, save_model=\"best_parameters_poc_three.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nuUZV3MJGjl",
        "outputId": "27ee6d9f-fcac-46c8-bd41-a89609807ec4"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50, Train Loss: 1.0703, Train Accuracy: 46.00%, Val Loss: 1.1305, Val Accuracy: 23.08%\n",
            "Epoch 2/50, Train Loss: 0.9114, Train Accuracy: 60.00%, Val Loss: 1.5603, Val Accuracy: 23.08%\n",
            "Epoch 3/50, Train Loss: 0.9213, Train Accuracy: 54.00%, Val Loss: 2.4342, Val Accuracy: 23.08%\n",
            "Epoch 4/50, Train Loss: 0.6891, Train Accuracy: 62.00%, Val Loss: 2.4201, Val Accuracy: 23.08%\n",
            "Epoch 5/50, Train Loss: 0.8092, Train Accuracy: 70.00%, Val Loss: 1.6757, Val Accuracy: 23.08%\n",
            "Epoch 6/50, Train Loss: 0.6408, Train Accuracy: 78.00%, Val Loss: 0.6468, Val Accuracy: 53.85%\n",
            "Epoch 7/50, Train Loss: 0.5626, Train Accuracy: 70.00%, Val Loss: 0.6280, Val Accuracy: 53.85%\n",
            "Epoch 8/50, Train Loss: 0.7207, Train Accuracy: 68.00%, Val Loss: 0.5880, Val Accuracy: 53.85%\n",
            "Epoch 9/50, Train Loss: 0.5749, Train Accuracy: 60.00%, Val Loss: 0.6156, Val Accuracy: 53.85%\n",
            "Epoch 10/50, Train Loss: 0.4572, Train Accuracy: 80.00%, Val Loss: 0.5375, Val Accuracy: 69.23%\n",
            "Epoch 11/50, Train Loss: 0.7610, Train Accuracy: 74.00%, Val Loss: 0.5195, Val Accuracy: 84.62%\n",
            "Epoch 12/50, Train Loss: 0.7177, Train Accuracy: 70.00%, Val Loss: 0.7271, Val Accuracy: 61.54%\n",
            "Epoch 13/50, Train Loss: 0.7618, Train Accuracy: 70.00%, Val Loss: 1.6384, Val Accuracy: 46.15%\n",
            "Epoch 14/50, Train Loss: 0.7152, Train Accuracy: 68.00%, Val Loss: 0.7397, Val Accuracy: 53.85%\n",
            "Epoch 15/50, Train Loss: 0.6112, Train Accuracy: 74.00%, Val Loss: 0.5937, Val Accuracy: 76.92%\n",
            "Epoch 16/50, Train Loss: 0.6510, Train Accuracy: 78.00%, Val Loss: 0.7718, Val Accuracy: 53.85%\n",
            "Epoch 17/50, Train Loss: 0.4411, Train Accuracy: 80.00%, Val Loss: 0.5999, Val Accuracy: 76.92%\n",
            "Epoch 18/50, Train Loss: 0.4924, Train Accuracy: 84.00%, Val Loss: 0.5134, Val Accuracy: 76.92%\n",
            "Epoch 19/50, Train Loss: 0.6347, Train Accuracy: 76.00%, Val Loss: 0.6317, Val Accuracy: 53.85%\n",
            "Epoch 20/50, Train Loss: 0.3763, Train Accuracy: 82.00%, Val Loss: 0.6565, Val Accuracy: 61.54%\n",
            "Epoch 21/50, Train Loss: 0.7655, Train Accuracy: 72.00%, Val Loss: 0.5966, Val Accuracy: 69.23%\n",
            "Epoch 22/50, Train Loss: 0.3802, Train Accuracy: 88.00%, Val Loss: 0.7437, Val Accuracy: 53.85%\n",
            "Epoch 23/50, Train Loss: 0.5753, Train Accuracy: 84.00%, Val Loss: 1.0725, Val Accuracy: 53.85%\n",
            "Epoch 24/50, Train Loss: 0.4289, Train Accuracy: 86.00%, Val Loss: 0.7252, Val Accuracy: 53.85%\n",
            "Epoch 25/50, Train Loss: 0.4287, Train Accuracy: 94.00%, Val Loss: 0.8860, Val Accuracy: 38.46%\n",
            "Epoch 26/50, Train Loss: 0.3330, Train Accuracy: 90.00%, Val Loss: 0.5082, Val Accuracy: 84.62%\n",
            "Epoch 27/50, Train Loss: 0.5562, Train Accuracy: 84.00%, Val Loss: 0.8025, Val Accuracy: 69.23%\n",
            "Epoch 28/50, Train Loss: 0.2425, Train Accuracy: 94.00%, Val Loss: 0.5690, Val Accuracy: 69.23%\n",
            "Epoch 29/50, Train Loss: 0.3735, Train Accuracy: 80.00%, Val Loss: 0.4640, Val Accuracy: 69.23%\n",
            "Epoch 30/50, Train Loss: 0.3630, Train Accuracy: 84.00%, Val Loss: 0.4983, Val Accuracy: 69.23%\n",
            "Epoch 31/50, Train Loss: 0.3099, Train Accuracy: 92.00%, Val Loss: 1.5933, Val Accuracy: 53.85%\n",
            "Epoch 32/50, Train Loss: 0.2543, Train Accuracy: 90.00%, Val Loss: 2.8970, Val Accuracy: 53.85%\n",
            "Epoch 33/50, Train Loss: 0.2214, Train Accuracy: 94.00%, Val Loss: 1.2091, Val Accuracy: 53.85%\n",
            "Epoch 34/50, Train Loss: 0.1527, Train Accuracy: 96.00%, Val Loss: 0.2728, Val Accuracy: 84.62%\n",
            "Epoch 35/50, Train Loss: 0.3042, Train Accuracy: 92.00%, Val Loss: 0.7351, Val Accuracy: 69.23%\n",
            "Epoch 36/50, Train Loss: 0.3719, Train Accuracy: 88.00%, Val Loss: 0.8788, Val Accuracy: 61.54%\n",
            "Epoch 37/50, Train Loss: 0.3807, Train Accuracy: 90.00%, Val Loss: 1.3619, Val Accuracy: 53.85%\n",
            "Epoch 38/50, Train Loss: 0.2302, Train Accuracy: 92.00%, Val Loss: 0.3828, Val Accuracy: 76.92%\n",
            "Epoch 39/50, Train Loss: 0.2441, Train Accuracy: 90.00%, Val Loss: 0.3544, Val Accuracy: 84.62%\n",
            "Epoch 40/50, Train Loss: 0.3706, Train Accuracy: 96.00%, Val Loss: 0.6270, Val Accuracy: 76.92%\n",
            "Epoch 41/50, Train Loss: 0.2485, Train Accuracy: 96.00%, Val Loss: 0.1873, Val Accuracy: 100.00%\n",
            "Epoch 42/50, Train Loss: 0.6143, Train Accuracy: 96.00%, Val Loss: 2.4576, Val Accuracy: 53.85%\n",
            "Epoch 43/50, Train Loss: 0.1376, Train Accuracy: 98.00%, Val Loss: 0.4520, Val Accuracy: 84.62%\n",
            "Epoch 44/50, Train Loss: 0.1297, Train Accuracy: 98.00%, Val Loss: 1.9666, Val Accuracy: 53.85%\n",
            "Epoch 45/50, Train Loss: 0.1068, Train Accuracy: 98.00%, Val Loss: 0.3539, Val Accuracy: 84.62%\n",
            "Epoch 46/50, Train Loss: 0.1864, Train Accuracy: 98.00%, Val Loss: 2.7330, Val Accuracy: 53.85%\n",
            "Epoch 47/50, Train Loss: 0.1565, Train Accuracy: 94.00%, Val Loss: 1.1865, Val Accuracy: 46.15%\n",
            "Epoch 48/50, Train Loss: 0.1894, Train Accuracy: 96.00%, Val Loss: 0.5249, Val Accuracy: 84.62%\n",
            "Epoch 49/50, Train Loss: 0.4404, Train Accuracy: 92.00%, Val Loss: 1.8734, Val Accuracy: 69.23%\n",
            "Epoch 50/50, Train Loss: 0.6914, Train Accuracy: 82.00%, Val Loss: 0.5981, Val Accuracy: 69.23%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testing_model_with_subset(model, \"best_parameters_poc_three.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "Rm2lKE3uMpqP",
        "outputId": "2a275455-2aa6-40a4-f5c5-a1fe9f8c4713"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-39-c585124ee4c3>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('best_parameters_poc_three.pth'))\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'best_parameters_poc_three.pth'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-c585124ee4c3>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Cargamos los mejores parámetros del modelo para hacer la evaluación.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'best_parameters_poc_three.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1063\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1064\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1065\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1066\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'best_parameters_poc_three.pth'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelo escogido\n",
        "\n",
        "En base a los resultados expuestos anteriormente se estará utilizando el modelo 3, puesto que presento el mejor rendimiento en su PoC. El entrenamiento y pruebas que se realizan a continuación se realizarán utilizando el tercer modelo."
      ],
      "metadata": {
        "id": "nWhI8cgz_PCW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instalar Weights and Biases"
      ],
      "metadata": {
        "id": "Mo2utl_N71r_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install wandb --upgrade"
      ],
      "metadata": {
        "id": "0JP_5WcA7dSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importar W&B y hacer login"
      ],
      "metadata": {
        "id": "SW3QSAzY8XOn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "LtwHieuw8aNi",
        "outputId": "742e2435-3fc1-4e14-97d2-76ceabaaab23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cargar datos y transformaciones para entrenamiento con dataset crudo"
      ],
      "metadata": {
        "id": "KIUlt9hH-N2k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_raw_data_transforms = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),  # Redimensionar a 128x128\n",
        "    transforms.Grayscale(num_output_channels=1),  # Convertir a escala de grises\n",
        "    transforms.ToTensor(),  # Convertir a tensor\n",
        "    transforms.RandomRotation(20),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])  # Normalización\n",
        "])\n",
        "\n",
        "test_raw_data_transforms = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),  # Redimensionar a 128x128\n",
        "    transforms.Grayscale(num_output_channels=1),  # Convertir a escala de grises\n",
        "    transforms.ToTensor(),  # Convertir a tensor\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])  # Normalización\n",
        "])\n",
        "\n",
        "# Definir las rutas a las carpetas\n",
        "train_raw_dir = './drive/MyDrive/Covid19-dataset/train'\n",
        "test_raw_dir = './drive/MyDrive/Covid19-dataset/test'\n",
        "\n",
        "train_raw_dataset = datasets.ImageFolder(root=train_raw_dir, transform=train_raw_data_transforms)\n",
        "test_raw_dataset = datasets.ImageFolder(root=test_raw_dir, transform=test_raw_data_transforms)\n",
        "\n",
        "# Definir DataLoader para el conjunto de entrenamiento con el subconjunto de datos\n",
        "train_raw_loader = DataLoader(train_raw_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# También puedes crear un DataLoader para el conjunto de prueba completo\n",
        "test_raw_loader = DataLoader(test_raw_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "LI-SPVEy-T25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Funciones de Training y Testing\n",
        "\n",
        "Se definen las funciones de training y testing que además utilizan weights and biases para llevar los registros del entrenamiento."
      ],
      "metadata": {
        "id": "nY9SrPyxsMAF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir la función de entrenamiento\n",
        "def train_model(model, train_loader, test_loader, criterion, optimizer, epochs=10):\n",
        "    for epoch in range(epochs):\n",
        "        model.train()  # Poner el modelo en modo de entrenamiento\n",
        "\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        # Training\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()  # Limpiar los gradientes\n",
        "            outputs = model(inputs)  # Hacer una predicción\n",
        "            loss = criterion(outputs, labels)  # Calcular la pérdida\n",
        "            loss.backward()  # Hacer backpropagation\n",
        "            optimizer.step()  # Actualizar los pesos\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "        train_loss = running_loss / len(train_loader)\n",
        "        train_accuracy = 100 * correct / total\n",
        "\n",
        "        # Validation\n",
        "        model.eval()  # Setear el modelo a evalución\n",
        "        val_running_loss = 0.0\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "        with torch.no_grad():  # Desabilitar gradientes para validación\n",
        "            for inputs, labels in test_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_running_loss += loss.item()\n",
        "\n",
        "                _, predicted = outputs.max(1)\n",
        "                val_total += labels.size(0)\n",
        "                val_correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "        val_loss = val_running_loss / len(test_loader)\n",
        "        val_accuracy = 100 * val_correct / val_total\n",
        "        wandb.log({\n",
        "            \"epoch\": epoch + 1,\n",
        "            \"train_loss\": train_loss,\n",
        "            \"train_accuracy\": train_accuracy,\n",
        "            \"val_loss\": val_loss,\n",
        "            \"val_accuracy\": val_accuracy\n",
        "        })\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, \"\n",
        "              f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, \"\n",
        "              f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%\")\n",
        "\n",
        "# Entrenar el modelo con evaluación.\n",
        "model = CNNModelWithTwoInception()\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "wandb.init(project=\"selected-model-b-three\")\n",
        "wandb.config = {\n",
        "    \"learning_rate\": 0.001,\n",
        "    \"epochs\": 50,\n",
        "    \"batch_size\": 32,\n",
        "    \"optimizer\": \"Adam\"\n",
        "}\n",
        "\n",
        "wandb.watch(model, log=\"all\", log_freq=10)\n",
        "train_model(model, train_raw_loader, test_raw_loader, criterion, optimizer, epochs=50)\n",
        "wandb.finish()"
      ],
      "metadata": {
        "id": "QxoAY1AYOtOg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "2d1a078e23b1417dafd08f41800defd7",
            "1ef034003c8e47c8a887dabbeeeb7de9",
            "540d64ceee8743f9ae9ef773c714eb89",
            "3013bf09801b4f748e2424cc98f3003b",
            "89febf560bdc4d74ba9e02d5a62e661a",
            "399bcf67cab144f0927e543527e9dc03",
            "fe12adf8aed44250bbf1230d153edba7",
            "60cf4d6bf9444bc582c54d2e763a8eb9"
          ]
        },
        "outputId": "521ba6d4-d96e-4621-8af0-cb07996147d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:xwgclgdf) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.011 MB of 0.011 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2d1a078e23b1417dafd08f41800defd7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">colorful-oath-2</strong> at: <a href='https://wandb.ai/iaredescnncnn-instituto-tecnol-gico-de-costa-rica/selected-model-b-three/runs/xwgclgdf' target=\"_blank\">https://wandb.ai/iaredescnncnn-instituto-tecnol-gico-de-costa-rica/selected-model-b-three/runs/xwgclgdf</a><br/> View project at: <a href='https://wandb.ai/iaredescnncnn-instituto-tecnol-gico-de-costa-rica/selected-model-b-three' target=\"_blank\">https://wandb.ai/iaredescnncnn-instituto-tecnol-gico-de-costa-rica/selected-model-b-three</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241013_194720-xwgclgdf/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:xwgclgdf). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241013_194746-ss4t5tpa</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/iaredescnncnn-instituto-tecnol-gico-de-costa-rica/selected-model-b-three/runs/ss4t5tpa' target=\"_blank\">rare-sunset-3</a></strong> to <a href='https://wandb.ai/iaredescnncnn-instituto-tecnol-gico-de-costa-rica/selected-model-b-three' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/iaredescnncnn-instituto-tecnol-gico-de-costa-rica/selected-model-b-three' target=\"_blank\">https://wandb.ai/iaredescnncnn-instituto-tecnol-gico-de-costa-rica/selected-model-b-three</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/iaredescnncnn-instituto-tecnol-gico-de-costa-rica/selected-model-b-three/runs/ss4t5tpa' target=\"_blank\">https://wandb.ai/iaredescnncnn-instituto-tecnol-gico-de-costa-rica/selected-model-b-three/runs/ss4t5tpa</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50, Train Loss: 1.0188, Train Accuracy: 49.00%, Val Loss: 1.1847, Val Accuracy: 39.39%\n",
            "Epoch 2/50, Train Loss: 0.8247, Train Accuracy: 61.35%, Val Loss: 2.8835, Val Accuracy: 39.39%\n",
            "Epoch 3/50, Train Loss: 0.7215, Train Accuracy: 67.33%, Val Loss: 3.8538, Val Accuracy: 39.39%\n",
            "Epoch 4/50, Train Loss: 0.6769, Train Accuracy: 67.73%, Val Loss: 2.6230, Val Accuracy: 40.91%\n",
            "Epoch 5/50, Train Loss: 0.5856, Train Accuracy: 73.31%, Val Loss: 1.7021, Val Accuracy: 48.48%\n",
            "Epoch 6/50, Train Loss: 0.5342, Train Accuracy: 77.29%, Val Loss: 0.4897, Val Accuracy: 80.30%\n",
            "Epoch 7/50, Train Loss: 0.5238, Train Accuracy: 72.11%, Val Loss: 0.4587, Val Accuracy: 65.15%\n",
            "Epoch 8/50, Train Loss: 0.4901, Train Accuracy: 78.49%, Val Loss: 0.4928, Val Accuracy: 63.64%\n",
            "Epoch 9/50, Train Loss: 0.4259, Train Accuracy: 80.08%, Val Loss: 0.5714, Val Accuracy: 74.24%\n",
            "Epoch 10/50, Train Loss: 0.4361, Train Accuracy: 80.48%, Val Loss: 0.9102, Val Accuracy: 69.70%\n",
            "Epoch 11/50, Train Loss: 0.3957, Train Accuracy: 86.06%, Val Loss: 0.4301, Val Accuracy: 84.85%\n",
            "Epoch 12/50, Train Loss: 0.3672, Train Accuracy: 86.85%, Val Loss: 0.6708, Val Accuracy: 74.24%\n",
            "Epoch 13/50, Train Loss: 0.3416, Train Accuracy: 85.66%, Val Loss: 0.5604, Val Accuracy: 66.67%\n",
            "Epoch 14/50, Train Loss: 0.3977, Train Accuracy: 82.07%, Val Loss: 1.2940, Val Accuracy: 68.18%\n",
            "Epoch 15/50, Train Loss: 0.4065, Train Accuracy: 83.67%, Val Loss: 0.5611, Val Accuracy: 63.64%\n",
            "Epoch 16/50, Train Loss: 0.3085, Train Accuracy: 88.84%, Val Loss: 0.4725, Val Accuracy: 83.33%\n",
            "Epoch 17/50, Train Loss: 0.3074, Train Accuracy: 88.05%, Val Loss: 0.2743, Val Accuracy: 87.88%\n",
            "Epoch 18/50, Train Loss: 0.2688, Train Accuracy: 89.64%, Val Loss: 0.2818, Val Accuracy: 87.88%\n",
            "Epoch 19/50, Train Loss: 0.2449, Train Accuracy: 88.05%, Val Loss: 0.5705, Val Accuracy: 80.30%\n",
            "Epoch 20/50, Train Loss: 0.3379, Train Accuracy: 86.06%, Val Loss: 0.4751, Val Accuracy: 86.36%\n",
            "Epoch 21/50, Train Loss: 0.2775, Train Accuracy: 88.05%, Val Loss: 1.0756, Val Accuracy: 68.18%\n",
            "Epoch 22/50, Train Loss: 0.2506, Train Accuracy: 90.04%, Val Loss: 0.2273, Val Accuracy: 86.36%\n",
            "Epoch 23/50, Train Loss: 0.2404, Train Accuracy: 90.44%, Val Loss: 0.3827, Val Accuracy: 77.27%\n",
            "Epoch 24/50, Train Loss: 0.2622, Train Accuracy: 90.04%, Val Loss: 0.1969, Val Accuracy: 92.42%\n",
            "Epoch 25/50, Train Loss: 0.2860, Train Accuracy: 86.45%, Val Loss: 0.4159, Val Accuracy: 84.85%\n",
            "Epoch 26/50, Train Loss: 0.2024, Train Accuracy: 91.24%, Val Loss: 0.3326, Val Accuracy: 80.30%\n",
            "Epoch 27/50, Train Loss: 0.2106, Train Accuracy: 90.84%, Val Loss: 0.2105, Val Accuracy: 90.91%\n",
            "Epoch 28/50, Train Loss: 0.2825, Train Accuracy: 87.65%, Val Loss: 0.9488, Val Accuracy: 57.58%\n",
            "Epoch 29/50, Train Loss: 0.2168, Train Accuracy: 91.24%, Val Loss: 0.1738, Val Accuracy: 87.88%\n",
            "Epoch 30/50, Train Loss: 0.2216, Train Accuracy: 91.24%, Val Loss: 0.1639, Val Accuracy: 90.91%\n",
            "Epoch 31/50, Train Loss: 0.1969, Train Accuracy: 93.63%, Val Loss: 0.8407, Val Accuracy: 77.27%\n",
            "Epoch 32/50, Train Loss: 0.1995, Train Accuracy: 93.63%, Val Loss: 0.1982, Val Accuracy: 87.88%\n",
            "Epoch 33/50, Train Loss: 0.2253, Train Accuracy: 91.24%, Val Loss: 0.2683, Val Accuracy: 92.42%\n",
            "Epoch 34/50, Train Loss: 0.1910, Train Accuracy: 92.83%, Val Loss: 0.4112, Val Accuracy: 83.33%\n",
            "Epoch 35/50, Train Loss: 0.2833, Train Accuracy: 91.24%, Val Loss: 0.4608, Val Accuracy: 77.27%\n",
            "Epoch 36/50, Train Loss: 0.2164, Train Accuracy: 93.23%, Val Loss: 0.3413, Val Accuracy: 80.30%\n",
            "Epoch 37/50, Train Loss: 0.1947, Train Accuracy: 92.03%, Val Loss: 0.3181, Val Accuracy: 75.76%\n",
            "Epoch 38/50, Train Loss: 0.1649, Train Accuracy: 93.23%, Val Loss: 0.3152, Val Accuracy: 78.79%\n",
            "Epoch 39/50, Train Loss: 0.1931, Train Accuracy: 92.03%, Val Loss: 0.2765, Val Accuracy: 89.39%\n",
            "Epoch 40/50, Train Loss: 0.1125, Train Accuracy: 96.02%, Val Loss: 0.2779, Val Accuracy: 92.42%\n",
            "Epoch 41/50, Train Loss: 0.1250, Train Accuracy: 96.02%, Val Loss: 0.1501, Val Accuracy: 92.42%\n",
            "Epoch 42/50, Train Loss: 0.1646, Train Accuracy: 93.63%, Val Loss: 1.1376, Val Accuracy: 77.27%\n",
            "Epoch 43/50, Train Loss: 0.2477, Train Accuracy: 91.24%, Val Loss: 2.1138, Val Accuracy: 66.67%\n",
            "Epoch 44/50, Train Loss: 0.1869, Train Accuracy: 91.63%, Val Loss: 2.0747, Val Accuracy: 69.70%\n",
            "Epoch 45/50, Train Loss: 0.1664, Train Accuracy: 94.42%, Val Loss: 0.1249, Val Accuracy: 93.94%\n",
            "Epoch 46/50, Train Loss: 0.1255, Train Accuracy: 95.22%, Val Loss: 0.0991, Val Accuracy: 93.94%\n",
            "Epoch 47/50, Train Loss: 0.1657, Train Accuracy: 94.82%, Val Loss: 0.3812, Val Accuracy: 80.30%\n",
            "Epoch 48/50, Train Loss: 0.1653, Train Accuracy: 93.63%, Val Loss: 0.2432, Val Accuracy: 84.85%\n",
            "Epoch 49/50, Train Loss: 0.1530, Train Accuracy: 94.02%, Val Loss: 0.0915, Val Accuracy: 93.94%\n",
            "Epoch 50/50, Train Loss: 0.1044, Train Accuracy: 96.81%, Val Loss: 0.0822, Val Accuracy: 96.97%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291,
          "referenced_widgets": [
            "e67129e61a61415d8f2e76c4ddbfefd5",
            "3c178c59a115437d89ff427f46cd7f56",
            "268784bd3f0e404a82fa7a8e03d427c7",
            "6ae100c748cd4a24a3daf05a423645cf",
            "c8f4d5286d7e485a9e917cc0ae5e93a1",
            "3f549524ce0e46f29ac593b82b6312b0",
            "7a5d8a2e705543df8e6e6055d5e825fe",
            "2f58941c0a5145399d413f84171048d2"
          ]
        },
        "id": "g8Xhwq8eXBJO",
        "outputId": "f3db64a1-4ae4-4282-bc33-9936eefabbab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.206 MB of 0.206 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e67129e61a61415d8f2e76c4ddbfefd5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train_accuracy</td><td>▁▃▄▄▅▄▅▆▆▆▆▆▆▇▇▇▆▇▇▇▆▇▇▇▇██▇▇▇▇███▇█████</td></tr><tr><td>train_loss</td><td>█▇▆▅▅▄▄▃▄▃▃▃▃▃▃▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▂▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▁▁▁▂▄▄▅▅▇▄▆▇▇▆▄▇▆▇▇▇▃▇▇▆▇▆▆▆▅▇▇▇▆▄██▆▇█</td></tr><tr><td>val_loss</td><td>▃█▆▄▂▂▂▃▂▂▃▂▂▁▁▂▃▁▂▁▁▃▁▁▂▁▂▂▁▁▁▁▁▃▅▁▁▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>50</td></tr><tr><td>train_accuracy</td><td>96.81275</td></tr><tr><td>train_loss</td><td>0.10439</td></tr><tr><td>val_accuracy</td><td>96.9697</td></tr><tr><td>val_loss</td><td>0.08218</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">rare-sunset-3</strong> at: <a href='https://wandb.ai/iaredescnncnn-instituto-tecnol-gico-de-costa-rica/selected-model-b-three/runs/ss4t5tpa' target=\"_blank\">https://wandb.ai/iaredescnncnn-instituto-tecnol-gico-de-costa-rica/selected-model-b-three/runs/ss4t5tpa</a><br/> View project at: <a href='https://wandb.ai/iaredescnncnn-instituto-tecnol-gico-de-costa-rica/selected-model-b-three' target=\"_blank\">https://wandb.ai/iaredescnncnn-instituto-tecnol-gico-de-costa-rica/selected-model-b-three</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241013_194746-ss4t5tpa/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "images = images.to(device)  # Mueve las imágenes a la GPU si está disponible\n",
        "correct = 0\n",
        "total = 0\n",
        "# debido a que no estamos entrenando, no necesitamos calcular los gradientes para las salidas\n",
        "with torch.no_grad():\n",
        "    for data in test_raw_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        # calcular outputs corriendo imagenes en la red\n",
        "        outputs = model(images)\n",
        "        # La clase con mayor valor es la que escogemos como salida\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy de la red en las imagenes de test: {100 * correct // total} %')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3j-NoEvaAw-",
        "outputId": "0e97d473-fe5f-49c5-ffd6-a4411ff5f0f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy de la red en las imagenes de test: 100 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bibliografía\n",
        "\n",
        "Bjorck, N., Gomes, C. P., Selman, B., & Weinberger, K. Q. (2018). Understanding batch normalization. Advances in neural information processing systems, 31."
      ],
      "metadata": {
        "id": "P4X5pSObsSI0"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2d1a078e23b1417dafd08f41800defd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1ef034003c8e47c8a887dabbeeeb7de9",
              "IPY_MODEL_540d64ceee8743f9ae9ef773c714eb89"
            ],
            "layout": "IPY_MODEL_3013bf09801b4f748e2424cc98f3003b"
          }
        },
        "1ef034003c8e47c8a887dabbeeeb7de9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89febf560bdc4d74ba9e02d5a62e661a",
            "placeholder": "​",
            "style": "IPY_MODEL_399bcf67cab144f0927e543527e9dc03",
            "value": "0.011 MB of 0.011 MB uploaded\r"
          }
        },
        "540d64ceee8743f9ae9ef773c714eb89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe12adf8aed44250bbf1230d153edba7",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_60cf4d6bf9444bc582c54d2e763a8eb9",
            "value": 1
          }
        },
        "3013bf09801b4f748e2424cc98f3003b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89febf560bdc4d74ba9e02d5a62e661a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "399bcf67cab144f0927e543527e9dc03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe12adf8aed44250bbf1230d153edba7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60cf4d6bf9444bc582c54d2e763a8eb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e67129e61a61415d8f2e76c4ddbfefd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3c178c59a115437d89ff427f46cd7f56",
              "IPY_MODEL_268784bd3f0e404a82fa7a8e03d427c7"
            ],
            "layout": "IPY_MODEL_6ae100c748cd4a24a3daf05a423645cf"
          }
        },
        "3c178c59a115437d89ff427f46cd7f56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8f4d5286d7e485a9e917cc0ae5e93a1",
            "placeholder": "​",
            "style": "IPY_MODEL_3f549524ce0e46f29ac593b82b6312b0",
            "value": "0.206 MB of 0.206 MB uploaded\r"
          }
        },
        "268784bd3f0e404a82fa7a8e03d427c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a5d8a2e705543df8e6e6055d5e825fe",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2f58941c0a5145399d413f84171048d2",
            "value": 1
          }
        },
        "6ae100c748cd4a24a3daf05a423645cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8f4d5286d7e485a9e917cc0ae5e93a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f549524ce0e46f29ac593b82b6312b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7a5d8a2e705543df8e6e6055d5e825fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f58941c0a5145399d413f84171048d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}